{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Histopathologic Cancer Detection using Convolutional Neural Network, and Transfer Learning.\n",
    "Description      : 1. Detected Cancer from Histopathologic images by retraining pretrained model “InceptionV3” with                            250000+ images of X-ray (6GB).\n",
    "                   2. For retraining, removed output layers, freezed first few layers and Fine-tuned model for two new label                   classes (Cancer and Normal).\n",
    "                   3. Attained testing accuracy 69.55 and loss 1.10.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.28.2018\n",
    "Comments         : Please use Anaconda editor for convenience.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Histopathologic Cancer Detection\n",
    "Dataset Link     : <a href=https://www.kaggle.com/c/histopathologic-cancer-detection>Histopathologic Cancer Detection (Kaggle)</a>\n",
    "                 : <a href=https://github.com/basveeling/pcam> PatchCamelyon (PCam) (GitHub)</a>\n",
    "                 : <a href=https://camelyon16.grand-challenge.org/Data>CAMELYON16 challenge Dataset (Original Dataset)</a>\n",
    "                 \n",
    "Original Paper   : <a href=https://jamanetwork.com/journals/jama/fullarticle/2665774>Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer</a> \n",
    "                   Authors: Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes van Diest \n",
    "                   JAMA (The Journal of the American Medical Association)\n",
    "                   <cite>\n",
    "                   Ehteshami Bejnordi B, Veta M, Johannes van Diest P, et al. Diagnostic Assessment of Deep Learning                        Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA.                                     2017;318(22):2199–2210. doi:10.1001/jama.2017.14585\n",
    "                   </cite>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Histopathologic Cancer Detection\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 220,025 (5.72 Gigabyte (GB))\n",
    "                          Training   : 132,016 (3.43 Gigabyte (GB))\n",
    "                          Validation : 44,005  (1.14 Gigabyte (GB))\n",
    "                          Testing    : 44,004  (1.14 Gigabyte (GB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 32\n",
    "Number of Epochs        : 20\n",
    "Training Time           : 1 day and 8 hour (33 Hours)\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 69.55%\n",
    "Loss                    : 1.10\n",
    "<!--Precision               : -->\n",
    "Recall                  : \n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Deletes file, if file exists \n",
    "def remove_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except:\n",
    "            print(\"Could not remove file : \", filename)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time for given type of representation\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "         \n",
    "    \n",
    "def reset_plot_propert(plot_property=None):\n",
    "    plot_property = {\n",
    "        'figsize':(15, 5),\n",
    "        'title':'title',\n",
    "        'xlabel': None,\n",
    "        'ylabel': None,\n",
    "        'legend': None,\n",
    "        'title_fontsize' : 18,\n",
    "        'label_fontsize':14, \n",
    "        'subplot':None}\n",
    "    return plot_property\n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, plot_property):\n",
    "    if plot_property['subplot']:\n",
    "        plt.subplot(plot_property['subplot'])\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(plot_property['title'], fontsize=plot_property['title_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, plot_property):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, plot_property)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, plot_property):\n",
    "    plt.figure(figsize=plot_property['figsize'])\n",
    "    \n",
    "    title = plot_property['title']\n",
    "    plot_property['title'] = title +\" (Training)\"\n",
    "    subplot_no = plot_property['subplot'] \n",
    "\n",
    "    count_bar_plot(training_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title +\" (Validation)\"\n",
    "    plot_property['subplot'] = subplot_no+1\n",
    "    count_bar_plot(validation_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title +\" (Testing)\"\n",
    "    plot_property['subplot'] = subplot_no+2\n",
    "    count_bar_plot(testing_dir, plot_property)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, image_transform_params, batch_params):       \n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center = image_transform_params['featurewise_center'], \n",
    "        samplewise_center = image_transform_params['samplewise_center'], \n",
    "        featurewise_std_normalization = image_transform_params['featurewise_std_normalization'],\n",
    "        samplewise_std_normalization = image_transform_params['samplewise_std_normalization'], \n",
    "        zca_whitening = image_transform_params['zca_whitening'], \n",
    "        zca_epsilon = image_transform_params['zca_epsilon'], \n",
    "        rotation_range = image_transform_params['rotation_range'], \n",
    "        width_shift_range = image_transform_params['width_shift_range'], \n",
    "        height_shift_range = image_transform_params['height_shift_range'], \n",
    "        brightness_range = image_transform_params['brightness_range'], \n",
    "        shear_range = image_transform_params['shear_range'], \n",
    "        zoom_range = image_transform_params['zoom_range'], \n",
    "        channel_shift_range = image_transform_params['channel_shift_range'], \n",
    "        fill_mode = image_transform_params['fill_mode'], \n",
    "        cval = image_transform_params['cval'], \n",
    "        horizontal_flip = image_transform_params['horizontal_flip'], \n",
    "        vertical_flip = image_transform_params['vertical_flip'], \n",
    "        rescale = image_transform_params['rescale'], \n",
    "        preprocessing_function = image_transform_params['preprocessing_function'], \n",
    "        data_format = image_transform_params['data_format'],\n",
    "        validation_split = image_transform_params['validation_split'], \n",
    "        dtype = image_transform_params['dtype'])     \n",
    "    \n",
    "\n",
    "    image_generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=batch_params['target_size'],\n",
    "        color_mode=batch_params['color_mode'],\n",
    "        classes = batch_params['classes'],\n",
    "        class_mode=batch_params['class_mode'],\n",
    "        batch_size=batch_params['batch_size'],\n",
    "        shuffle=batch_params['shuffle'],\n",
    "        seed=batch_params['seed'],\n",
    "        save_to_dir=batch_params['save_to_dir'], \n",
    "        save_prefix=batch_params['save_prefix'],\n",
    "        save_format=batch_params['save_format'],\n",
    "        follow_links=batch_params['follow_links'], \n",
    "        subset=batch_params['subset'],\n",
    "        interpolation=batch_params['interpolation'])\n",
    "    \n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, model_obj, training_obj, callbacks):    \n",
    "    # create the base pre-trained model\n",
    "    if model_obj['model_name'] == 'InceptionV3':\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=model_obj['include_top'])\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation=activation['activation'])(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        # compile model with loss, optimizer and metrics \n",
    "        model.compile(model_obj['optimizer'], loss=model_obj['loss'], metrics=model_obj['metrics'])\n",
    "\n",
    "        callbacks['tensorboard'].set_model(model) \n",
    "    \n",
    "        # train the model on the new data for a few epochs\n",
    "        model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = training_obj['steps_per_epoch'],\n",
    "            epochs=training_obj['epochs'],\n",
    "            # verbose=training_obj['verbose'], \n",
    "            callbacks=training_obj['callbacks'],\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=training_obj['validation_steps'],\n",
    "            class_weight = training_obj['class_weight'],\n",
    "            # max_queue_size = training_obj['max_queue_size'], \n",
    "            # workers = training_obj['workers'], \n",
    "            # use_multiprocessing = training_obj['use_multiprocessing'], \n",
    "            # shuffle = training_obj['shuffle'], \n",
    "            initial_epoch = training_obj['initial_epoch'])\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if model_obj['print_layers']:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:model_obj['non_trainable_index']]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[model_obj['non_trainable_index']:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    if not callbacks:\n",
    "        model.compile(model_obj['optimizer'], loss=model_obj['loss'], metrics=model_obj['metrics'])\n",
    "        \n",
    "        model_obj['tensorboard'].set_model(model) \n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, plot_property):\n",
    "    plt.figure(figsize=plot_property['figsize'])\n",
    "    \n",
    "    plt.subplot(plot_property['subplot'][0])\n",
    "    \n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    \n",
    "    plt.title(plot_property['title'][0], fontsize=plot_property['title_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'][0], fontsize=plot_property['label_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'][0], fontsize=plot_property['label_fontsize'])\n",
    "    \n",
    "    plt.legend(plot_property['legend'][0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(plot_property['subplot'][1])\n",
    "    \n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    \n",
    "    plt.title(plot_property['title'][1], fontsize=plot_property['title_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'][1], fontsize=plot_property['label_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'][1], fontsize=plot_property['label_fontsize'])\n",
    "    \n",
    "    plt.legend(plot_property['legend'][1], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "        \n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "    \n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    \n",
    "    cls_report_print = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    \n",
    "    cls_report = classification_report(test_generator.classes, y_classes, target_names=classes, output_dict=True)\n",
    "    \n",
    "    if print_report: \n",
    "        print(cls_report_print)\n",
    "        \n",
    "    return y_preds, y_classes, CM, cls_report, cls_report_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    \n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "        \n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, plot_obj):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    \n",
    "    if plot_obj['subplot']:\n",
    "        plt.subplot(plot_obj['subplot'])\n",
    "        \n",
    "    plt.title(plot_obj['title'], fontsize=plot_obj['title_fontsize'])\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(plot_obj['xlabel'], fontsize=plot_obj['label_fontsize'])\n",
    "    plt.ylabel(plot_obj['ylabel'], fontsize=plot_obj['label_fontsize'])\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, plot_obj):\n",
    "    plt.figure(figsize=plot_obj['fig_size'])\n",
    "    \n",
    "    title = plot_obj['title']\n",
    "    xlabel=plot_obj['xlabel']\n",
    "    ylabel=plot_obj['ylabel']\n",
    "    subplot_no=plot_obj['subplot']\n",
    "    \n",
    "    plot_obj['title'] = title[0]\n",
    "    plot_obj['xlabel'] = xlabel[0]\n",
    "    plot_obj['ylabel'] = ylabel[0]\n",
    "    plot_obj['subplot'] = subplot_no[0]\n",
    "    \n",
    "    line_plot_over_epochs(array[0], plot_obj)\n",
    "    \n",
    "    plot_obj['title'] = title[1]\n",
    "    plot_obj['xlabel'] = xlabel[1]\n",
    "    plot_obj['ylabel'] = ylabel[1]\n",
    "    plot_obj['subplot'] = subplot_no[1]\n",
    "    \n",
    "    line_plot_over_epochs(array[1], plot_obj)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    \n",
    "    fig, ax = plot_confusion_matrix(\n",
    "        conf_mat=CM ,  \n",
    "        figsize=figsize, \n",
    "        hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    \n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_filename, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "        \n",
    "    model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "    if not os.path.isdir(model_path):\n",
    "        return None\n",
    "    \n",
    "    reset_graph(model)\n",
    "\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    accuracy, loss =  model_evaluate(\n",
    "        model, \n",
    "        test_generator, \n",
    "        print_report=False)\n",
    "    \n",
    "    y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "\n",
    "    precision = cls_report[class_name]['precision'] *100\n",
    "    recall =  cls_report[class_name]['recall'] *100\n",
    "    f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "\n",
    "\n",
    "\n",
    "    results1[model_filename] = [accuracy, loss]\n",
    "    results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "    print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "    print(\"*\"*80)\n",
    "    show_confusion_matrix(test_generator, y_classes, classes)\n",
    "    print(cls_report_print)\n",
    "    print(\"%s%.2f%s\"% (\"Current Accuracy: \", accuracy, \"%\"))\n",
    "    print(\"%s%.2f\"% (\"Current Loss: \", loss))\n",
    "    print(\"%s%.2f%s\"% (\"Current Precision: \", precision, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current Recall: \", recall, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current F1_score: \", f1_score, \"%\"))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    \n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "\n",
    "    report = {\"Accuracy\" : accuracy, \n",
    "              \"Loss\" : loss,\n",
    "              \"Precision\" : precision,\n",
    "              \"Recall\": recall,\n",
    "              \"F1-Score\":f1_score}\n",
    "\n",
    "\n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    filenames=[]\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    loss_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    \n",
    "    \n",
    "    best_accuracy=0\n",
    "    best_accuracy_file=\"\"\n",
    "    \n",
    "    best_loss=1000\n",
    "    best_loss_file=\"\"\n",
    "    \n",
    "    \n",
    "    best_precision=0\n",
    "    best_precision_file=\"\"\n",
    "    \n",
    "    best_recall=0\n",
    "    best_recall_file=\"\"\n",
    "    \n",
    "    best_f1_score=0\n",
    "    best_f1_score_file=\"\"\n",
    "    \n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    model = None\n",
    "    reset_graph(model)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for model_filename in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "            \n",
    "            current_accuracy, current_loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "            y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "            \n",
    "            current_precision = cls_report[class_name]['precision'] *100\n",
    "            current_recall =  cls_report[class_name]['recall'] *100\n",
    "            current_f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "            \n",
    "            filenames.append(model_file)\n",
    "            \n",
    "            accuracy_list.append(current_accuracy)\n",
    "            loss_list.append(current_loss)\n",
    "            \n",
    "            precision_list.append(current_precision)\n",
    "            recall_list.append(current_recall)\n",
    "            f1_score_list.append(current_f1_score)\n",
    "            \n",
    "            \n",
    "            results1[model_filename] = [current_accuracy, current_loss]\n",
    "            results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "                \n",
    "            if current_accuracy>=best_accuracy:\n",
    "                best_accuracy=current_accuracy\n",
    "                best_accuracy_file=model_filename\n",
    "\n",
    "            if current_loss<=best_loss:\n",
    "                best_loss=current_loss\n",
    "                best_loss_file=model_filename\n",
    "                \n",
    "            \n",
    "            if current_precision>=best_precision:\n",
    "                best_precision=current_precision\n",
    "                best_precision_file=model_filename\n",
    "\n",
    "            if current_recall>=best_recall:\n",
    "                best_recall=current_recall\n",
    "                best_recall_file=model_filename\n",
    "                \n",
    "            if current_f1_score>=best_f1_score:\n",
    "                best_f1_score=current_f1_score\n",
    "                best_f1_score_file=model_filename\n",
    "                    \n",
    "\n",
    "            if details or i%5==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "                print(\"*\"*80)\n",
    "                show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                print(cls_report_print)\n",
    "                print(\"%s%.2f%s\"% (\"Current Accuracy: \", current_accuracy, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Current Loss: \", current_loss))\n",
    "                print(\"%s%.2f%s\"% (\"Current Precision: \", current_precision, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current Recall: \", current_recall, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current F1_score: \", current_f1_score, \"%\"))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "    \n",
    "    report = {\"Best Accuracy\" : [best_accuracy, best_accuracy_file], \n",
    "                   \"Best Loss\" : [best_loss, best_loss_file],\n",
    "                   \"Best Precision\" : [best_precision, best_precision_file],\n",
    "                   \"Best Recall\": [best_recall, best_recall_file],\n",
    "                   \"Best F1-Score\":[best_f1_score, best_f1_score_file]}\n",
    "    \n",
    "    \n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 23:23:56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=1\n",
    "date_time(x)\n",
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train_final\"\n",
    "testing_dir = input_directory+ r\"test_final\"\n",
    "validation_dir = input_directory+ r\"validation_final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDUAAAEZCAYAAACHJh4LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3X2YXVV59/HvTxBEEQENiAkKanxBWlBSpNVaFcVgbcGqT+FRSZWa1mLVvin62KKirbYqSotWlAhYlVKslSoYI2KtrSLhRRAQiYgSQIiEdxQM3s8few0cJjOTmcyZlzPz/VzXXGefe6+99tpnTu45uc/ae6eqkCRJkiRJGjQPmOkBSJIkSZIkbQ6LGpIkSZIkaSBZ1JAkSZIkSQPJooYkSZIkSRpIFjUkSZIkSdJAsqghSZIkSZIGkkUNTZkkz06yYabHAZBkWZK1SW5P8pKZHs9kJXlBkv+e4n0sS3LeVLUfR387J/lRkh371ac0l5lzp85U5Nz2+hzSlh/bXqudxmj/tSRvm8T+tmj7+LXN7WNYfw9K8oMki/vRnzRfmKunznR8Pt7E/t+R5N/62N/Tknw3yQP71edcZVFjHmgfhCrJs4bF1yT5gxka1rRJsiXwYWB5VW1bVZ8dpd0uST7S/iN9R5IfJzk1yT7TO+KxJQlwDHBUe35J+2N0e5K7ktzT8/z2JI/enP1U1UlVNe5jn2j7cfR3PXAq8Nf96lOaDubcOZ9zP5Tk66O0/USSL0x0H1V1ZXutbpjcaO8dx/OS/HzYPu5p+zi3H/uoqp8DHwD+vh/9SdPNXD3nc/WUfD7u2d+3kvxlb6yqjqqql02m32H9nQ9cASzvV59zlUWN+eNG4H3tH/zA2sxK5SOBBwMXjdHvo4BzgV2BFwLbAXsA/wn83mbscyodAGwFnA1QVU9pf4y2BY4G/nvoefv58fAOBqjiuwI4PMm2Mz0QaYLMuXM05wIfBX4zyZN6GyV5GPB/2vr54lPAC5LsPtMDkTaTuXqO5urN+Xw8S60A3jDTg5jtLGrMHx8DFgGHjrRypKlwSd6e5Cs9zyvJ65KsbpXa/02yKMmfJbk6yY1J3j1C38tadXd9khN7/4Oa5OFJTmjbr2uV35171l+V5G+SnJ3kDmDEqXFJXpLkO0luaY8vbvFfBy5vzS5vldmtR+jincAdwIur6pL2jdbtVfXJqvp/ra+9kvxXkp8muSnJmUke1zOG5yW5IMmtrU3va/fgJO9L8sP2OnwpyeN71h+S5LIktyW5PsmJIx1nczDwlaqqMdoMf32+keQDSU5PcivwhiSPTrKyve63JPl6kqf2bPOHSb43rI+/T/K5Ns41SX5nEu2T5K+TXNPeO+9rr++906ur6jLgFuC54z1WaZYw587RnFtVlwL/A7xmWLtXAOuBM9o+/izJ5W0fP0ryriQjfu5K8vj2+35ke54kb0s3LfzGJO8D0tN+25Zbf9KOf3WS/du6R9P9h2Pr3PeN5MuTbNn2sV9PPy9LcnHP7/F3e9b9YZLvteO4pr2OH+49hqq6GTgfuDe3SwPGXD1Hc/V4JHlgex2vSHJzus/Ce/WsX9pet1vb7+GLLf5x4NeAd7fX7jst/p70zNZrOfpN7fW5vfW1b8/6rZP8U+v72iRvTM+pic1Xgd2T7DHe45qPLGrMH3cAfwP87ShJa7xeQZc0FgA/p/uHtgPwOLr/eP5lkt/oab8F3YedXwWeDDwBeD/cO03sP4AC9gQeA9wGfHrYPl8D/DmwLfD54QNqiflTwJHAw4G3Ap9J8vSq+ibwlNb0ia0ye9cIx/VC4N+q6hdjHHsBbwcWArsBtwP/0rP+ZOBY4GGtTe8fsI8DTwL2o6uMnwN8oSXTBwOfBI6oqocCjwVOGGMcTwMuHWP9aF5N99o/jG664QOAf6R73R9JV6n/bLrpiKN5FfDe1sdHgZOSPGgz278K+BO6134Xum9LfmOEPr5Ld8zSIDHnzu2c+1HgsCRb9cReA5xQVfe051cDS+m+2Xwx8Ed0eW88/gB4Hd3vche631Pv7/kBwGnAYrrfwWl0+XvH9u3j7wB39Xwj+anhO0jym3Sv4V+2Pt4G/FvuP6X8cXTvt8fSvZb/Fxg+tfpizNEaXObquZ2rN+W9dDM8ngc8AvhX4EtJtmvrPwW8p6q2o5ut8g8AVfWHdDNY/l977fbaqOf7vJou/29PVxDvPYajgGcDS+jeK08Gdu7duKruAK7CPDsmixrzyyfokuJkpjC9v6rWVtWddB+iHgm8varurqrvAN+hq1z2enNV3dKukfA3wLJ03/Ts036OaOvvBN4EPDfJop7tP1ZVF1TnZyOM6VXAZ6vqzKraUFVfBD5Hl0TGawFwzVgNquqiqjq7qu6qqluAdwD7JXlIa3I3XULaubU5GyDJI+i+AfiTqrq+qu5u2+4CPL1t+wvgSe0D6R1VNdZFjnYAbp3AsQ05tar+q72Od1bVVVX1hbb8M7oPtLvT/dEYzaer6ltV9UvgeO77g7057Q8DPlJV32mvyXuAkc4nvxXwYqEaRObc0Q16zv03us9QQ996Pp3uPx/3flitqtOq6oftdTyf7sPx/mMdc4+h/HhBG//RwLqevm+tqk9V1W1V9Yuqek9btWSc/UP3ezy1qla23+N/Aqdz/9/j7XTvt7uq6vt007qH78McrUFnrh7doOfqUSXZgu7LtT+vqh+11+g4urx3QM/+H59k56r6eVV9bbz99ziuqr5XVRvo/kY8pecLvsOAv237/xldkXmk/5+bZzfBosY8Ut23R28C3prk4ZvZzXU9y3cCN7T/sPbGHjpsmx/1LF8FbE1XDd29LV/fpnzdDPyArsL96GHbjGVX4MphsR+0+Hito6sejyrJ45L8e7ppuLfSVVuhOxaAg+i+Nbs4yaVJ3tjiQ+caX9RznOuBBwK7tj9WL6T7Ru8HSc5L8n/HGMpNdN/8TdRVw45npyT/ku6CT7f2rF8wRh+9v/872uPw3/d42y+k571RVUX3zeZw29G9XtJAMeeOaaBzbnUXyfwk9128bTlwRlXdm8PSnfKxuk2pvgX4Y8bOr70W0fN7aL/ze8//Tjdl+7gkV7Zp0Te3MY63fxjf7/H6Ye+3O9j4/WaO1kAzV49poHP1JjyK7nVeNbT/NoaF3Pca/TawF3BJuruQHDGB/ocM/ywcYNs2I2cX7v9Z+LZ2HMOZZzdhrGnmmoOq6swk36arCPe6HdgiydZ13/SzR/Vpt4+hS6LQTUu7C/gp3T/iO4AdhyX+4cZaB91/hIdfpOyxjPwf5NGcAbw0yTtq9Cl2/wxcC/xqVd2YZE+6abcBaJX4329J6pnAl5NcRHf6BMDiqlo3Qr+0yu/XWtX4d+mmEZ9TVT8YofkFdBdpmqjhr+N76f7g7FtVP0myPV0ina6LZV1D994A7p1uOdIf2j3pXntp4JhzRzUXcu5H6T7oPhX4feDec6DTXTjzk63vlVX1iyQfpMtn43EN3e9uqL8HcP//zPwV8Ay6ae0/qqpK0pu/N/U7hP78HqE7ptMmuI00q5irRzUXcvVorqObRfLMqrp4lP2fR3f8oTtNZGWSC6rqfxlfnh1Vy9vX0b0P/gcgyUPpZpzcq8142Y3u+DQKZ2rMT39F961S7zc6l9Ml7j9M8oAkzwRe2qf9/V2S7ZLsRHfO3Sdbkl4NXAh8aKgynmRB7n9xnPE4EXhJuntTb5HkQLorMn9iAn0cRXdO4mlJntz6eUiSQ5O8q7XZju6PzM1tytw7hzZOslW6Cz49os04uIku2W2o7hZ9nwY+nGRha799khenu9jbzuku5PSw9m3Bza3bofOyh/sPxj+FeSzb0X1zcFNLou/tQ58T8Ungj5P8arqrdr8J2Km3Qbq7CzyM7txUaVCZczc28Dm3ugsZfwP4LN03aGf2rN6W7gP9OmBDunPpXz6B12coP+6V7rodb+X+75/t6L61vZHugqDv5P7fAv+kxcf6RvZE4P8keX57/X+b7j8N4/49prvjyz50FyaVBp25emMDn6tH004H+SfgmCSPbft/aJID274fkuQV6U59ud/YWxc/oZuBMhmfBI5Md/H+beg+iw8vljwHuKqqLpnkvuY0ixrzUKuYnkLPFK023elVwF/Q3W3iDcBJfdjdPcAX6Sq2l9NNg/vzts9f0l1U6QHAeUluo7tA0LMnsoNWLV0GvI8u4fw98Iqq+tYE+riG7lzH64Av0527dlkb39B9u/8M+M227r+BLwzr5veB7yW5ne685KOq6utt3Wvojv9r7TgvprvYWtEd/xHAVW3dccCyqrpqlOGupPuQ/OzxHt8o/ppuit16uj+e/zXJ/ibqE3TfdH6J7g/DArqLLvVeqOrVwIr2/pQGkjl3xD7mSs79KN03ob0XCKV963c03e/iZrrzpD8z5otyf5+g+/bzTLrXaHvgf3vWv4/uPxHXAVfQ/R7W9uz/0ja2C9JNqd5oynZ7rV4NHNO2/zvg0KpaPYFxvhz4clUNn+IuDRxz9Yh9zJVcPZojgVXAF9OdOnM58Ic9618BfL+N/TTgTVX17bbufXS3974pyfkT2Gevd9AVx8+nm7XzfbrP5cM/C39oM/ufN1Ljv+uNpFkiyVLgrVX1rJkeS7+km1p4DfD6qhq6ddm3gadV1Y0zOzpJ89lczLmTle5Cd98FXljdRUQlaUYNeq5Odyr4emBJVZ2fZG+6i0zvPcbpP8KihqQZku4c8ZfQVe23BP4f3S2vHlvd1bMlSZKkOamdevSrwNfoTiH8R7pbt/5K7+w/bZqnn0iaSW+ku43rtcCz6L7xs6AhSZKkuW4L4B/oTg/6AfBw4CALGhPnTA1JkiRJkjSQnKkhSZIkSZIG0pYzPYCZ9IhHPKJ22223mR6GJN3Peeed99OqWrDploPPPCxpNppPeRjMxZJmp/Hm4nld1Nhtt91YvXoidy6TpKmX5EczPYbpYh6WNBvNpzwM5mJJs9N4c7Gnn0iSJEmSpIFkUUOSJEmSJA2kaStqJPmzJJck+W6SzyR5UJLdk5yT5Iok/5pkq9Z26/Z8TVu/W08/b2nxy5O8oCe+tMXWJDlyuo5LkiRJkiTNjGkpaiRZCLweWFJVe9Ldk/cQ4L3AMVW1mO7+vIe3TQ4HbqqqxwPHtHYk2aNt9xRgKfDhJFsk2QI4DjgQ2AM4tLWVJEmSJElz1HSefrIlsE2SLYEHA9cBzwVOa+tPAg5uywe157T1+ydJi59SVXdV1Q+BNcC+7WdNVV1ZVXcDp7S2kiRJkiRpjpqWokZVXQO8D/gxXTHjFuA84Oaq2tCarQUWtuWFwNVt2w2t/cN748O2GS2+kSTLk6xOsnrdunWTPzhJkiRJkjQjpuv0kx3oZk7sDjwKeAjdqSLD1dAmo6ybaHzjYNXxVbWkqpYsWDBvbj8uSZIkSdKcM12nnzwP+GFVrauqXwD/DvwGsH07HQVgEXBtW14L7ArQ1j8MWN8bH7bNaHFJkiRJkjRHTVdR48fAfkke3K6NsT9wKXA28NLWZhnw+bZ8entOW//VqqoWP6TdHWV3YDHwbeBcYHG7m8pWdBcTPX0ajkuSJEmSJM2QLTfdZPKq6pwkpwHnAxuAC4DjgS8CpyR5V4ud0DY5AfhkkjV0MzQOaf1ckuRUuoLIBuCIqroHIMnrgJV0d1ZZUVWXTMexSZP143f+ykwPQVPg0X9z8UwPQdIEmIvnJnOxNDjMw3PTdOThaSlqAFTVUcBRw8JX0t25ZHjbnwMvG6WfdwPvHiF+BnDG5EcqSZIkSZIGwXTe0lWSJEmSJKlvLGpIkiRJkqSBZFFDkiRJkiQNJIsakiRJkiRpIFnUkKR5IMmuSc5OclmSS5K8ocXfnuSaJBe2nxf2bPOWJGuSXJ7kBT3xpS22JsmRPfHdk5yT5Iok/9pusS1JaszFktR/FjUkaX7YAPxFVT0Z2A84Iskebd0xVbV3+zkDoK07BHgKsBT4cJItkmwBHAccCOwBHNrTz3tbX4uBm4DDp+vgJGlAmIslqc8sakjSPFBV11XV+W35NuAyYOEYmxwEnFJVd1XVD4E1dLfg3hdYU1VXVtXdwCnAQUkCPBc4rW1/EnDw1ByNJA0mc7Ek9Z9FDUmaZ5LsBjwVOKeFXpfkoiQrkuzQYguBq3s2W9tio8UfDtxcVRuGxUfa//Ikq5OsXrduXR+OSJIGj7lYkvrDooYkzSNJtgU+C7yxqm4FPgI8DtgbuA54/1DTETavzYhvHKw6vqqWVNWSBQsWTPAIJGnwmYslqX+2nOkBSJKmR5IH0n2I/lRV/TtAVV3fs/5jwBfa07XArj2bLwKubcsjxX8KbJ9ky/YNYW97SVJjLpak/nKmhiTNA+086xOAy6rqAz3xXXqavRj4bls+HTgkydZJdgcWA98GzgUWt6vrb0V3AbvTq6qAs4GXtu2XAZ+fymOSpEFjLpak/nOmhiTND88AXglcnOTCFnsr3RXz96abnnwV8EcAVXVJklOBS+mu1n9EVd0DkOR1wEpgC2BFVV3S+nszcEqSdwEX0H1wlyTdx1wsSX1mUUOS5oGq+gYjn2t9xhjbvBt49wjxM0barqqupLsivyRpBOZiSeo/Tz+RJEmSJEkDyaKGJEmSJEkaSBY1JEmSJEnSQLKoIUmSJEmSBtK0FDWSPDHJhT0/tyZ5Y5Idk6xKckV73KG1T5Jjk6xJclGSp/X0tay1vyLJsp74Pkkubtsc226ZJUmSJEmS5qhpKWpU1eVVtXdV7Q3sA9wJfA44EjirqhYDZ7XnAAfS3Yd7MbAc+AhAkh2Bo4Cn013V+aihQkhrs7xnu6XTcGiSJEmSJGmGzMTpJ/sDP6iqHwEHASe1+EnAwW35IODk6nwL2D7JLsALgFVVtb6qbgJWAUvbuu2q6ptVVcDJPX1JkiRJkqQ5aCaKGocAn2nLO1fVdQDtcacWXwhc3bPN2hYbK752hPhGkixPsjrJ6nXr1k3yUCRJkiRJ0kyZ1qJGkq2A3wX+bVNNR4jVZsQ3DlYdX1VLqmrJggULNjEMSZIkSZI0W033TI0DgfOr6vr2/Pp26gjt8YYWXwvs2rPdIuDaTcQXjRCXJEmSJElz1HQXNQ7lvlNPAE4Hhu5gsgz4fE/8sHYXlP2AW9rpKSuBA5Ls0C4QegCwsq27Lcl+7a4nh/X0JUmSJEmS5qAtp2tHSR4MPB/4o57we4BTkxwO/Bh4WYufAbwQWEN3p5RXAVTV+iRHA+e2du+sqvVt+bXAicA2wJntR5IkSZIkzVHTVtSoqjuBhw+L3Uh3N5ThbQs4YpR+VgArRoivBvbsy2AlSZIkSdKsNxN3P5EkSZIkSZo0ixqSJEmSJGkgWdSQJEmSJEkDyaKGJEmSJEkaSBY1JEmSJEnSQLKoIUmSJEmSBpJFDUmSJEmSNJAsakiSJEmSpIFkUUOSJEmSJA0kixqSJEmSJGkgWdSQJEmSJEkDyaKGJEmSJEkaSBY1JEmSJEnSQLKoIUmSJEmSBpJFDUmSJEmSNJAsakiSJEmSpIFkUUOSJEmSJA2kaStqJNk+yWlJvpfksiS/nmTHJKuSXNEed2htk+TYJGuSXJTkaT39LGvtr0iyrCe+T5KL2zbHJsl0HZskzXZJdk1ydsu/lyR5Q4ubhyVpmpiLJan/pnOmxoeAL1XVk4C9gMuAI4GzqmoxcFZ7DnAgsLj9LAc+Al3CB44Cng7sCxw1lPRbm+U92y2dhmOSpEGxAfiLqnoysB9wRJI9MA9L0nQyF0tSn01LUSPJdsCzgBMAquruqroZOAg4qTU7CTi4LR8EnFydbwHbJ9kFeAGwqqrWV9VNwCpgaVu3XVV9s6oKOLmnL0ma96rquqo6vy3fRldYXoh5WJKmjblYkvpvumZqPBZYB3wiyQVJPp7kIcDOVXUddEke2Km1Xwhc3bP92hYbK752hLgkaZgkuwFPBc7BPCxJM8JcLEn9MV1FjS2BpwEfqaqnAndw37S6kYx07l9tRnzjjpPlSVYnWb1u3bqxRy1Jc0ySbYHPAm+sqlvHajpCzDwsSX1gLpak/pmuosZaYG1VndOen0ZX5Li+TZOjPd7Q037Xnu0XAdduIr5ohPhGqur4qlpSVUsWLFgwqYOSpEGS5IF0H6I/VVX/3sLmYUmaRuZiSeqvaSlqVNVPgKuTPLGF9gcuBU4Hhq7WvAz4fFs+HTisXfF5P+CWNhVvJXBAkh3axZAOAFa2dbcl2a9d4fmwnr4kad5rufEE4LKq+kDPKvOwJE0Tc7Ek9d+W07ivPwU+lWQr4ErgVXRFlVOTHA78GHhZa3sG8EJgDXBna0tVrU9yNHBua/fOqlrfll8LnAhsA5zZfiRJnWcArwQuTnJhi70VeA/mYUmaLuZiSeqzaStqVNWFwJIRVu0/QtsCjhilnxXAihHiq4E9JzlMSZqTquobjHyuNZiHJWlamIslqf+m65oakiRJkiRJfWVRQ5IkSZIkDSSLGpIkSZIkaSBZ1JAkSZIkSQPJooYkSZIkSRpIFjUkSZIkSdJAsqghSZIkSZIGkkUNSZIkSZI0kCxqSJIkSZKkgWRRQ5IkSZIkDSSLGpIkSZIkaSBZ1JAkSZIkSQNpy5kewCDa569OnukhaIqc9w+HzfQQJI2TuXhuMg9Lg8M8PDeZhzVonKkhSZIkSZIGkkUNSZIkSZI0kCZc1EiyY5KnTsVgJEmbZh6WpJlnLpak2WHcRY0kD0/yReCnwDda7GVJPjhVg5Mk3cc8LEkzz1wsSbPLRGZqfIguee8K3N1i/wW8sN+DkiSNyDwsSTPPXCxJs8hEihrPA/64qq4BCqCqbgB2Hs/GSa5KcnGSC5OsbrEdk6xKckV73KHFk+TYJGuSXJTkaT39LGvtr0iyrCe+T+t/Tds2Ezg2SRoEk8rDkqS+MBdL0iwykaLGBuB+hYIk2wM3TaCP51TV3lW1pD0/EjirqhYDZ7XnAAcCi9vPcuAjbX87AkcBTwf2BY4aKoS0Nst7tls6gXFJ0iDoRx6WJE2OuViSZpGJFDW+Arw3Se82bwO+NIn9HwSc1JZPAg7uiZ9cnW8B2yfZBXgBsKqq1lfVTcAqYGlbt11VfbOqCji5py9JmiumIg9LkibGXCxJs8iWE2j7V8AXgBuBhya5AfgB8KJxbl/Al5MU8NGqOh7YuaquA6iq65Ls1NouBK7u2XZti40VXztCfCNJltPN6ODRj370OIcuSbPCZPOwJGnyzMWSNIuMu6hRVeuS7Ac8A9gN+BHwP1X1y3F28YyqurYVLlYl+d4YbUe6HkZtRnzjYFdMOR5gyZIlI7aRpNmoD3lYkjRJ5mJJml0mMlODdmrHN5JcWFW3T3Dba9vjDUk+R3dNjOuT7NJmaewC3NCar6W7ovSQRcC1Lf7sYfGvtfiiEdpL0pwymTwsSeoPc7EkzR7jvqZGkgclOSbJzcAtSW5O8sEk24xj24ckeejQMnAA8F3gdGDoDibLgM+35dOBw9pdUPYDbmmnqawEDkiyQ7tA6AHAyrbutiT7tbueHNbTlyTNCZPJw5Kk/jAXS9LsMpELhf4j3TS7lwO/CrwC+HXg2HFsuzNdNfs7wLeBL1bVl4D3AM9PcgXw/PYc4AzgSmAN8DHgTwCqaj1wNHBu+3lniwG8Fvh42+YHwJkTODZJGgSTycOSpP4wF0vSLDKR008OBn6lqn7Snl+S5DzgYuA1Y21YVVcCe40QvxHYf4R4AUeM0tcKYMUI8dXAnps4BkkaZJudhyVJfWMulqRZZCIzNe4Ebh0Wu7XFJUlTzzwsSTPPXCxJs8hEihpHAx9L8kiAdmHPfwbeMRUDkyRtxDwsSTPPXCxJs8hETj85BtgGOCTJhrZtAQclOWaoUVVt198hSpIa87AkzTxzsSTNIhMparx0ykYhSRoP87AkzTxzsSTNIhMpany1qn4xZSORJG3KpPJwkhXAi4AbqmrPFns73YXt1rVmb62qM9q6twCHA/cAr6+qlS2+FPgQsAXw8ap6T4vvDpwC7AicD7yyqu7e3PFK0iy12bnYPCxJ/TeRa2pcl+T9SZ40ZaORJI1lsnn4RGDpCPFjqmrv9jP0QXoP4BDgKW2bDyfZIskWwHHAgcAewKGtLcB7W1+LgZvoPohL0lwzmVx8IuZhSeqriRQ1DgN2A76T5BtJDkuyzdQMS5I0gknl4ar6OrB+nM0PAk6pqruq6ofAGmDf9rOmqq5s3/6dQnceeYDnAqe17U+iu+2hJM01m52LzcOS1H/jLmpU1RlV9RJgV+DzwJHAtUn+KcleUzVASVJnCvPw65JclGRFkh1abCFwdU+btS02WvzhwM1VtWFYfCNJlidZnWT1unXrRmoiSbPWFOXiac3DYC6WNHdMZKYGAFV1Q1X9A/AHwJXAnwDfSvJfSfbs8/gkScP0OQ9/BHgcsDdwHfD+Fs9Iu96M+MbBquOraklVLVmwYMEEhytJs0Mfc/G052EwF0uaOyZU1EiyQ5LXJ/kO8EXgv+jO5XtkW/5s/4coSRrS7zxcVddX1T1V9UvgY3TTmqH7hm/XnqaLgGvHiP8U2D7JlsPikjTn9DMXm4claXLGXdRIcgpwDd1trP4BWFRVf15V36uqW4C3A4+aklFKkqYkDyfZpefpi4HvtuXTgUOSbN2upr8Y+DZwLrA4ye5JtqK7iN3pVVXA2dx3q8NldNOyJWlO6XcuNg9L0uRM5JauPwH2qarLRlpZVb/sufKyJKn/JpWHk3wGeDbwiCRrgaOAZyfZm26K8lXAH7W+LklyKnApsAE4oqruaf28DlhJdyvBFVV1SdvFm4FTkrwLuAA4YXKHK0mz0mbnYvOwJPXfJosaSS6uql+pqjduqm1VXb2pNpKkielXHq6qQ0cIj/qBt6reDbx7hPgZwBkjxK/kvmnTkjSn9CMXm4clqf/Gc/rJblM9CEnSmHab6QFIkszFkjQbjaeoMepVkyVJ08I8LEkzz1wsSbPQeK6psXWSvxmrQVW9s0/jkSRtzDwsSTPPXCxJs9B4ihoPAH5zjPVWrSVpapmHJWnmmYslaRYaT1HjZ1X1/H7sLMkWwGrgmqp6Ubs91SnAjsD5wCur6u4kWwMnA/sANwK/X1VXtT7eAhwsPOB8AAAYG0lEQVQO3AO8vqpWtvhS4EN0V4H+eFW9px9jlqRZoG95WJK02czFkjQLjeeaGv30BqD39lfvBY6pqsXATXTFCtrjTVX1eOCY1o52e6xDgKcAS4EPJ9miFUuOAw4E9gAO9faykiRJkiTNbeMpaqQfO0qyCPht4OPteYDnAqe1JicBB7flg9pz2vr9W/uDgFOq6q6q+iGwhu62VfsCa6rqyqq6m272x0H9GLckzQJ9ycOSpEkxF0vSLDSeosb9Zjyks8tm7OuDwJuAX7bnDwdurqoN7flaYGFbXghcDdDW39La3xsfts1o8Y0kWZ5kdZLV69at24zDkKRp1688LEnafOZiSZqFNlnUqKqrAZJsm+QE4Gd0MyRIcnCSozbVR5IXATdU1Xm94ZF2t4l1E41vHKw6vqqWVNWSBQsWjDFqSZod+pGHJUmTYy6WpNlpItfUeD+wM/AM4O4WOxf4/XFs+wzgd5NcRXdqyHPpZm5sn2ToYqWLgGvb8lpgV4C2/mHA+t74sG1Gi0vSXDKZPCxJ6g9zsSTNIhMparwIeHmbbVEAVXUN8KhNbVhVb6mqRVW1G92FPr9aVS8HzgZe2potAz7flk9vz2nrv1pV1eKHJNm63TllMfBtuj8ki5PsnmSrto/TJ3BskjQINjsPS5L6xlwsSbPIeG7pOiR00+zuCyTbArdPYv9vBk5J8i7gAuCEFj8B+GSSNXQzNA4BqKpLkpwKXApsAI6oqnvaWF4HrKS7peuKqrpkEuOSpNloKvKwJGlizMWSNItMpKjxP8BbgHf0xP6UbrbFuFXV14CvteUr6e5cMrzNz4GXjbL9u4F3jxA/AzhjImORpAHTlzwsSZoUc7EkzSITKWr8OfDVJK8Atk1yMfBAYP8pGZkkaTjzsCTNPHOxJM0i4y5qVNXVSfakO49wd+BHwBeq6mdjbylJ6gfzsCTNPHOxJM0uE5mpQVXdBXwWIMmDgF9OxaAkSSMzD0vSzDMXS9LsMe67nyR5V5J92/Lz6S7guT7JAVM1OEnSfczDkjTzzMWSNLtM5Jauy4DvteW/prtzyRGMcNFOSdKUMA9L0swzF0vSLDKR00+2q6pbkzwE2At4blVtSPLBKRqbJOn+zMOSNPPMxZI0i0ykqHFjkicBewLntOS9zRSNS5K0MfOwJM08c7EkzSITKWp8EDivLb+8PT4LuKyvI5IkjcY8LEkzz1wsSbPIRG7pemySM4ENVfXDFv4hsHxKRiZJuh/zsCTNPHOxJM0uE72l6xXDnn+/v8ORJI3FPCxJM89cLEmzx7iLGu1cwbcB+wMLgAytq6rH9n9okqRe5mFJmnnmYkmaXSZyS9djgIOBTwI7A+8H7gJWTMG4JEkbMw9L0swzF0vSLDKRosbvAL9TVcfRnUN4HPAS4DlTMjJJ0nDmYUmaeeZiSZpFJlLU2LaqrmzLdyfZqqouBX5tCsYlSdqYeViSZp65WJJmkYlcKPSHSZ5cVZcB3wNeneRm4JapGZokaRjzsCTNPHOxJM0iEylq/B3waLp7cB8NfA7YGnjtFIxLkrQx87AkzTxzsSTNIpssaiTZGfitqvrXoVhVrUqyA3Ao8KUpHJ8kzXvmYUmaeeZiSZqdxnNNjTcDi4cHq+oXwKPaeknS1DEPS9LMMxdL0iw0nqLGC4GPj7JuBfCiTXWQ5EFJvp3kO0kuSfKOFt89yTlJrkjyr0m2avGt2/M1bf1uPX29pcUvT/KCnvjSFluT5MhxHJckDYpJ52GAJCuS3JDkuz2xHZOsanl46BtH0jm25dSLkjytZ5tlrf0VSZb1xPdJcnHb5tgk2ayjlaTZqR+fic3DktRn4ylqPLKqrh9pRVXdADxyHH3cBTy3qvYC9gaWJtkPeC9wTFUtBm4CDm/tDwduqqrH090L/L0ASfYADgGeAiwFPpxkiyRbAMcBBwJ7AIe2tpI0F/QjDwOcSJc7ex0JnNXy8FntOXT5dHH7WQ58BLoP38BRwNOBfYGjhj6AtzbLe7Ybvi9JGmT9yMUnYh6WpL4aT1Hj7iS7jLSixX+xqQ6qc3t7+sD2U8BzgdNa/CTg4LZ8UHtOW79/qzQfBJxSVXdV1Q+BNXTJfF9gTVVdWVV3A6e0tpI0F0w6DwNU1deB9cPCvfl2eB4+ueXvbwHbt329AFhVVeur6iZgFV2hehdgu6r6ZlUVcHJPX5I0F/TjM7F5WJL6bDxFjf8B/nSUdUcA/z2eHbUZFRcCN9Al3x8AN1fVhtZkLbCwLS8ErgZo628BHt4bH7bNaPGRxrE8yeokq9etWzeeoUvSTOtLHh7FzlV1HUB73KnFJ5pvF7bl4fGNmIclDaipysXTnofBXCxp7hjPLV3fDfx3kgXAZ4Br6BLkocDLgWeOZ0dVdQ+wd5Lt6W599eSRmrXHkc7/qzHiIxVnaoQYVXU8cDzAkiVLRmwjSbNMX/LwBE00D48W3zhoHpY0mKY7F09ZHgZzsaS5Y5MzNapqNfC7wG8BXwEubY+/BfxuVZ0/kR1W1c3A14D96KbRDRVWFgHXtuW1wK4Abf3D6Kbq3Rsfts1ocUkaeP3Ow8NcPzSduj3e0OITzbdr2/LwuCTNCVOYi83DkjQJ4zn9hKpaVVVPAJ4I/CbwxKp6QlV9ZTzbJ1nQZmiQZBvgecBlwNnAS1uzZcDn2/Lp7Tlt/VfbuYGnA4e0u6PsTncBpG8D5wKL291UtqK7mOjp4xmbJA2CyebhMfTm2+F5+LB29f39gFvatOiVwAFJdmgXpjsAWNnW3ZZkv3YNpMN6+pKkOWGKcrF5WJImYTynn9yrqq4ArtiM/ewCnNTuUvIA4NSq+kKSS4FTkrwLuAA4obU/AfhkkjV0MzQOafu/JMmpdJXxDcAR7bQWkryOLslvAayoqks2Y5ySNKtNIg+T5DPAs4FHJFlLd/X89wCnJjkc+DHwstb8DLrbF64B7gRe1fa/PsnRdMVkgHdW1dBF715Ld2X/bYAz248kzTmbm4vNw5LUfxMqamyuqroIeOoI8Svp7lwyPP5z7kvow9e9m+6cxuHxM+iSvyRpBFV16Cir9h+hbdFd+G6kflYAK0aIrwb2nMwYJWkuMw9LUv+N6/QTSZIkSZKk2caihiRJkiRJGkgWNSRJkiRJ0kCyqCFJkiRJkgaSRQ1JkiRJkjSQLGpIkiRJkqSBZFFDkiRJkiQNJIsakiRJkiRpIFnUkCRJkiRJA8mihiRJkiRJGkgWNSRJkiRJ0kCyqCFJkiRJkgaSRQ1JkiRJkjSQLGpIkiRJkqSBZFFDkiRJkiQNJIsakiRJkiRpIFnUkCRJkiRJA2laihpJdk1ydpLLklyS5A0tvmOSVUmuaI87tHiSHJtkTZKLkjytp69lrf0VSZb1xPdJcnHb5tgkmY5jkyRJkiRJM2O6ZmpsAP6iqp4M7AcckWQP4EjgrKpaDJzVngMcCCxuP8uBj0BXBAGOAp4O7AscNVQIaW2W92y3dBqOS5IkSZIkzZBpKWpU1XVVdX5bvg24DFgIHASc1JqdBBzclg8CTq7Ot4Dtk+wCvABYVVXrq+omYBWwtK3brqq+WVUFnNzTlyRJkiRJmoOm/ZoaSXYDngqcA+xcVddBV/gAdmrNFgJX92y2tsXGiq8dIT7S/pcnWZ1k9bp16yZ7OJIkSZIkaYZMa1EjybbAZ4E3VtWtYzUdIVabEd84WHV8VS2pqiULFizY1JAlSZIkSdIsNW1FjSQPpCtofKqq/r2Fr2+njtAeb2jxtcCuPZsvAq7dRHzRCHFJkiRJkjRHTdfdTwKcAFxWVR/oWXU6MHQHk2XA53vih7W7oOwH3NJOT1kJHJBkh3aB0AOAlW3dbUn2a/s6rKcvSZIkSZI0B205Tft5BvBK4OIkF7bYW4H3AKcmORz4MfCytu4M4IXAGuBO4FUAVbU+ydHAua3dO6tqfVt+LXAisA1wZvuRJEmSJElz1LQUNarqG4x83QuA/UdoX8ARo/S1AlgxQnw1sOckhilJkiRJkgbItN/9RJIkSZIkqR8sakiSJEmSpIFkUUOSJEmSJA0kixqSJEmSJGkgWdSQJJHkqiQXJ7kwyeoW2zHJqiRXtMcdWjxJjk2yJslFSZ7W08+y1v6KJMtG258k6f7Mw5K0eSxqSJKGPKeq9q6qJe35kcBZVbUYOKs9BzgQWNx+lgMfge7DN3AU8HRgX+CooQ/gkqRxMQ9L0gRZ1JAkjeYg4KS2fBJwcE/85Op8C9g+yS7AC4BVVbW+qm4CVgFLp3vQkjSHmIclaRMsakiSAAr4cpLzkixvsZ2r6jqA9rhTiy8Eru7Zdm2LjRa/nyTLk6xOsnrdunV9PgxJGljTlofBXCxp7thypgcgSZoVnlFV1ybZCViV5HtjtM0IsRojfv9A1fHA8QBLlizZaL0kzVPTlofBXCxp7nCmhiSJqrq2Pd4AfI7uXOzr23Rm2uMNrflaYNeezRcB144RlyRtgnlYkjaPRQ1JmueSPCTJQ4eWgQOA7wKnA0NXzl8GfL4tnw4c1q6+vx9wS5sWvRI4IMkO7cJ0B7SYJGkM5mFJ2nyefiJJ2hn4XBLo/i58uqq+lORc4NQkhwM/Bl7W2p8BvBBYA9wJvAqgqtYnORo4t7V7Z1Wtn77DkKSBZR6WpM1kUUOS5rmquhLYa4T4jcD+I8QLOGKUvlYAK/o9Rkmay8zDkrT5PP1EkiRJkiQNJIsakiRJkiRpIFnUkCRJkiRJA8mihiRJkiRJGkjTUtRIsiLJDUm+2xPbMcmqJFe0xx1aPEmOTbImyUVJntazzbLW/ooky3ri+yS5uG1zbNqloyVJkiRJ0tw1XTM1TgSWDosdCZxVVYuBs9pzgAOBxe1nOfAR6IogwFHA04F9gaOGCiGtzfKe7YbvS5IkSZIkzTHTUtSoqq8Dw++RfRBwUls+CTi4J35ydb4FbJ9kF+AFwKqqWl9VNwGrgKVt3XZV9c12e6uTe/qSJEmSJElz1ExeU2PnqroOoD3u1OILgat72q1tsbHia0eIjyjJ8iSrk6xet27dpA9CkiRJkiTNjNl4odCRrodRmxEfUVUdX1VLqmrJggULNnOIkiRJkiRpps1kUeP6duoI7fGGFl8L7NrTbhFw7Sbii0aIS5IkSZKkOWwmixqnA0N3MFkGfL4nfli7C8p+wC3t9JSVwAFJdmgXCD0AWNnW3ZZkv3bXk8N6+pIkSZIkSXPUltOxkySfAZ4NPCLJWrq7mLwHODXJ4cCPgZe15mcALwTWAHcCrwKoqvVJjgbObe3eWVVDFx99Ld0dVrYBzmw/kiRJkiRpDpuWokZVHTrKqv1HaFvAEaP0swJYMUJ8NbDnZMYoSZIkSZIGy2y8UKgkSZIkSdImWdSQJEmSJEkDyaKGJEmSJEkaSBY1JEmSJEnSQLKoIUmSJEmSBpJFDUmSJEmSNJAsakiSJEmSpIFkUUOSJEmSJA0kixqSJEmSJGkgWdSQJEmSJEkDyaKGJEmSJEkaSBY1JEmSJEnSQLKoIUmSJEmSBpJFDUmSJEmSNJAsakiSJEmSpIFkUUOSJEmSJA0kixqSJEmSJGkgWdSQJEmSJEkDaU4VNZIsTXJ5kjVJjpzp8UjSfGMelqSZZy6WNJ/MmaJGki2A44ADgT2AQ5PsMbOjkqT5wzwsSTPPXCxpvpkzRQ1gX2BNVV1ZVXcDpwAHzfCYJGk+MQ9L0swzF0uaV7ac6QH00ULg6p7na4GnD2+UZDmwvD29Pcnl0zC2QfYI4KczPYjpkvctm+khzHXz5/10VCaz9WP6NYxpZh6eOvPm3455eFrMm/fTJHLxoOZhMBdPlXnz78Y8PC3mzftpOj4Tz6WixkivVm0UqDoeOH7qhzM3JFldVUtmehyaG3w/zXnm4Snivx31k++nOc9cPAX8d6N+8v3UX3Pp9JO1wK49zxcB187QWCRpPjIPS9LMMxdLmlfmUlHjXGBxkt2TbAUcApw+w2OSpPnEPCxJM89cLGlemTOnn1TVhiSvA1YCWwArquqSGR7WXOC0RPWT76c5zDw8pfy3o37y/TSHmYunjP9u1E++n/ooVRudYidJkiRJkjTrzaXTTyRJkiRJ0jxiUUOSJEmSJA0kixpzXJJHJjklyQ+SXJrkjCRPmOlxafAkqSTv73n+l0nePs1jODHJS6dzn1I/mIvVL+ZiafOYh9Uv5uHZx6LGHJYkwOeAr1XV46pqD+CtwM7TOYYkvs/mhruA30vyiM3ZOMmcuTCxNBHmYvWZuViaIPOw+sw8PMv4D2tuew7wi6r656FAVV0IXJDkrCTnJ7k4yUEASXZLclmSjyW5JMmXk2zT1j0+yVeSfKdt97gW/6sk5ya5KMk7hvXzYeB87n+vdA2uDXRXav6z4SuSPKa9py5qj49u8ROTfCDJ2cB7k7w9yUntvXVVkt9L8vftffilJA9s2/1Ne199N8nx7cOINKjMxeonc7E0ceZh9ZN5eJaxqDG37QmcN0L858CLq+ppdEn+/T3/QBYDx1XVU4CbgZe0+KdafC/gN4DrkhzQ2u8L7A3sk+RZrf0TgZOr6qlV9aMpODbNjOOAlyd52LD4P9H9vn+V7r1ybM+6JwDPq6q/aM8fB/w2cBDwL8DZVfUrwM9aHOCfqurXqmpPYBvgRVNyNNL0MBer38zF0sSYh9Vv5uFZxKLG/BTgb5NcBHwFWMh90+9+2CrX0CX/3ZI8FFhYVZ8DqKqfV9WdwAHt5wK66vOT6BI6wI+q6lvTcjSaNlV1K3Ay8Pphq34d+HRb/iTwzJ51/1ZV9/Q8P7OqfgFcDGwBfKnFLwZ2a8vPSXJOkouB5wJP6dtBSLOHuVibxVws9Y15WJvFPDy7eD7P3HYJMNIFZF4OLAD2qapfJLkKeFBbd1dPu3voKoKjTXMK8HdV9dH7BZPdgDs2e9Sa7T5I9wf7E2O0qZ7l4e+FuwCq6pdJflFVQ21/CWyZ5EHAh4ElVXV1ugsvPQhpcJmLNRXMxdL4mYc1FczDs4QzNea2rwJbJ3nNUCDJrwGPAW5oyfs57fmoWiVybZKDWx9bJ3kwsBJ4dZJtW3xhkp2m6Fg0S1TVeuBU4PCe8P8Ch7TllwPfmMQuhpL1T9t7yys7a9CZi9V35mJpQszD6jvz8OxhUWMOa9W+FwPPT3f7qkuAtwNnAEuSrKb7x/a9cXT3SuD1bXre/wKPrKov002v+mabEnUa8ND+H4lmofcDvVd8fj3wqvb+eCXwhs3tuKpuBj5GN/XuP4BzJzFOacaZizWFzMXSOJiHNYXMw7NA7pvlIkmSJEmSNDicqSFJkiRJkgaSRQ1JkiRJkjSQLGpIkiRJkqSBZFFDkiRJkiQNJIsakiRJkiRpIFnUkCRJkiRJA8mihgQkWZLkP5KsS3Jrku8n+WCSXaZh37slqSSLpnpfkjRbmYclaeaZizWILGpo3kvyfOAbwOXA3lW1HfBbwI3tUZI0hczDkjTzzMUaVBY1JPgw8OmqenNVXQNQVddV1dFVdUqSByf5UJKrk/y0Va8fPbRxkq8leVtvh63K/My2/PYkZyX52yQ3tJ939DT/Tnu8PMntSf56io9XkmYb87AkzTxzsQaSRQ3Na0meADwe+PQYzY4B9ms/jwF+Cvxnki0msKtnAT8GHgX8DvDWJM9o6/Zqj0+sqm2r6ugJ9CtJA808LEkzz1ysQWZRQ/PdgvZ4zUgrkzwAOAx4W1VdU1V3AG8EngzsO4H9fL+q/rmqNlTVOcCFwJJJjFuS5grzsCTNPHOxBpZFDc1369rjwlHWLwAeBFw5FKiq24EbgF0nsJ/rhj2/A3joBLaXpLnKPCxJM89crIFlUUPzWlV9H1gDHDpKk3XAXcDuQ4Ek2wI7AVe30O3w/9u5W2UOojgMwO+vMiIz/l1xDa6BJLkDTTRGMqJxD4orkCRBQVMUV6CYESSOsBvUHWZ2Ds9Tz+75KG94Z/dk+dv4YuI2Pic+D/BnyGGA+clieqbUgGQ/yd54adEiSapqraoOk+wmuUhyUlWLqlpKcpbkKcnd+P5Dkp2qWq2qlSSnE9d/yRDiG79wFoAeyWGA+cliuqTU4N9rrV0n2UqymeSxqt6S3GZonm+SHGQI6fsMFxutJ9lurX2MU5xnCPTnDP8FXk1c/z3JcZLLqnqtqqMfHwqgI3IYYH6ymF5Va23uPQAAAABM5ksNAAAAoEtKDQAAAKBLSg0AAACgS0oNAAAAoEtKDQAAAKBLSg0AAACgS0oNAAAAoEtKDQAAAKBLXzhknpKncylyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_property = reset_plot_propert(plot_property=None)\n",
    "\n",
    "plot_property['figsize'] = (18,4)\n",
    "\n",
    "plot_property['title_fontsize']=13\n",
    "plot_property['label_fontsize']=13\n",
    "\n",
    "plot_property['title'] = \"Number of Cases\"\n",
    "\n",
    "plot_property['xlabel']=\"Count\"\n",
    "plot_property['ylabel']=\"CaseType\"\n",
    "\n",
    "plot_property['subplot']=131\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, plot_property)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (Image Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Adjustment for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "# class_weight=None\n",
    "# class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of labels/classes/categories\n",
    "#------------------------------------------------#\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "# Image normalization\n",
    "#----------------------#\n",
    "norm=255.0\n",
    "\n",
    "# recscaling\n",
    "#----------------------#\n",
    "rescale=1./norm\n",
    "\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Image Data Generator\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=False, vertical_flip=False, rescale=None, preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Parameters\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# featurewise_center=False\n",
    "# samplewise_center=False\n",
    "# featurewise_std_normalization=False\n",
    "# samplewise_std_normalization=False\n",
    "# zca_whitening=False\n",
    "# zca_epsilon=1e-06\n",
    "# rotation_range=0\n",
    "# width_shift_range=0.0\n",
    "# height_shift_range=0.0\n",
    "# brightness_range=None\n",
    "# shear_range=0.0\n",
    "# zoom_range=0.0\n",
    "# channel_shift_range=0.0\n",
    "# fill_mode='nearest'\n",
    "# cval=0.0\n",
    "# horizontal_flip=False\n",
    "# vertical_flip=False\n",
    "# rescale=None\n",
    "# preprocessing_function=None\n",
    "# data_format=None\n",
    "# validation_split=0.0\n",
    "# dtype=None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Parameter Map\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "def reset_image_augmentation_params():\n",
    "    image_transform_params = {\n",
    "        'featurewise_center' : False, \n",
    "        'samplewise_center' : False, \n",
    "        'featurewise_std_normalization' : False, \n",
    "        'samplewise_std_normalization' : False, \n",
    "        'zca_whitening' : False, \n",
    "        'zca_epsilon' : 1e-06, \n",
    "        'rotation_range' : 0,\n",
    "        'width_shift_range' : 0.0, \n",
    "        'height_shift_range' : 0.0, \n",
    "        'brightness_range' : None, \n",
    "        'shear_range' : 0.0, \n",
    "        'zoom_range' : 0.0, \n",
    "        'channel_shift_range' : 0.0, \n",
    "        'fill_mode' : 'nearest', \n",
    "        'cval' : 0.0, \n",
    "        'horizontal_flip' : False, \n",
    "        'vertical_flip' : False, \n",
    "        'rescale' : None, \n",
    "        'preprocessing_function' : None, \n",
    "        'data_format' : None, \n",
    "        'validation_split' : 0.0, \n",
    "        'dtype' : None, \n",
    "    }\n",
    "    return image_transform_params\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Parameter Adjustment\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "image_transform_params = reset_image_augmentation_params()\n",
    "\n",
    "image_transform_params['horizontal_flip'] =  True\n",
    "image_transform_params['vertical_flip'] =  True\n",
    "image_transform_params['rescale'] =  rescale\n",
    "# image_transform_params['validation_split'] =  0.0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Batch Generator\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# flow_from_directory(directory, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False, subset=None, interpolation='nearest')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Parameters\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# directory\n",
    "# target_size=(256, 256)\n",
    "# color_mode='rgb'\n",
    "# classes=None\n",
    "# class_mode='categorical'\n",
    "# batch_size=32\n",
    "# shuffle=True\n",
    "# seed=None\n",
    "# save_to_dir=None\n",
    "# save_prefix=''\n",
    "# save_format='png'\n",
    "# follow_links=False\n",
    "# subset=None\n",
    "# interpolation='nearest'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Parameter Map\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "def reset_batch_params():\n",
    "    batch_params = {\n",
    "        'target_size' : (256, 256),\n",
    "        'color_mode':'rgb',\n",
    "        'classes' : None,\n",
    "        'class_mode':'categorical',\n",
    "        'batch_size' : 32,\n",
    "        'shuffle':True,\n",
    "        'seed':None,\n",
    "        'save_to_dir':None, \n",
    "        'save_prefix':'',\n",
    "        'save_format':'png', \n",
    "        'follow_links':False, \n",
    "        'subset':None, \n",
    "        'interpolation':'nearest'\n",
    "    }\n",
    "    \n",
    "    return batch_params\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Parameter Adjustment\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Reset Batch Properties\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "batch_params = reset_batch_params()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Target Image dimention after Image Processing\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "batch_params['target_size'] = (299, 299) \n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Classes\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "batch_params['classes'] = ['Normal', 'Cancer']\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Class mode\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Properties - 'binary', 'categorical', 'sparse'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "batch_params['class_mode']='categorical'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Batch Size for trainning, validation and testing\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "batch_params['batch_size'] = 128\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132016 images belonging to 2 classes.\n",
      "Found 44005 images belonging to 2 classes.\n",
      "Found 44004 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, image_transform_params, batch_params)       \n",
    "\n",
    "image_transform_params = reset_image_augmentation_params()\n",
    "image_transform_params['rescale'] =  rescale\n",
    "batch_params['shuffle'] = False\n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, image_transform_params, batch_params)       \n",
    "\n",
    "batch_params['batch_size'] = 128\n",
    "test_generator = get_transformed_image_batch(testing_dir, image_transform_params, batch_params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Configuration\n",
    "### Setting Output Directory (Model and Log) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model Directory\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "model_dir=output_directory + r\"models/\"+time.strftime('%Y-%m-%d %H-%M-%S')+\"/\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Log Directory\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "log_dir=output_directory + r\"logs/\"+time.strftime('%Y-%m-%d %H-%M-%S')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "# Create Output Directory (Model and Log)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model File Name Configuration\n",
    "#------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Initial Trainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "init_model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Trainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "model_file=model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Retrainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "retrain_model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape=(3,150,150)\n",
    "input_shape=(3,299,299)\n",
    "\n",
    "activation='relu'\n",
    "# activation2='sigmoid'\n",
    "activation2='softmax'\n",
    "\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "\n",
    "pool_size=(2, 2)\n",
    "\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Configuration\n",
    "\n",
    "#### Base Model - InceptionV3 (pretrained) initial training settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception base top layer discarded\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "non_trainable_index = 249\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_optimizer=optimizers.Adam()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# init_epochs=1\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "print_layers=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning Parameters\n",
    "##### Settings for Loss, Optimizer and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "# Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "# Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "# Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "# Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.optimizers.X\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# learning rate = 1.0/0.1/0.01/0.001/0.0001/0.00001/0.000001\n",
    "# Decay = decay=1e-5/ 1e-6\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_optimizer=optimizers.Adam()\n",
    "optimizer=optimizers.Adam()\n",
    "ret_optimizer=optimizers.Adam()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# loss Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Loss Functions\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error',\n",
    "# 'squared_hinge', 'hinge', 'categorical_hinge', 'logcosh',\n",
    "# 'categorical_crossentropy', 'sparse_categorical_crossentropy', 'binary_crossentropy',\n",
    "# 'kullback_leibler_divergence', 'poisson', 'cosine_proximity'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.loss.X ??\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_loss='categorical_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "ret_loss='categorical_crossentropy'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Performance Metrics\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Metrics\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 'binary_accuracy', 'categorical_accuracy', 'sparse_categorical_accuracy', \n",
    "# 'top_k_categorical_accuracy', 'sparse_top_k_categorical_accuracy\n",
    "# None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.metrics.X\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_metrics=['accuracy']\n",
    "metrics=['accuracy']\n",
    "ret_metrics=['accuracy']\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_pred(y_true, y_pred):\n",
    "#     return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Parameters (Epochs, Steps, Verbose)\n",
    "#### Main model training parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Epochs\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# epochs = 10/20/30/50\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Number of Epochs\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_epochs = 10\n",
    "epochs = 10\n",
    "ret_epochs = 10\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Trainning Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "# steps_per_epoch=60/600\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Steps Per Epoch\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_steps_per_epoch=len(train_generator)\n",
    "steps_per_epoch=len(train_generator)\n",
    "ret_steps_per_epoch=len(train_generator)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Validation Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# validation_steps=1/20/200\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Validation Per Epoch\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_validation_steps=len(validation_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "ret_validation_steps=len(validation_generator)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 0=nothing \n",
    "# 1=each line\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_verbose=1\n",
    "verbose=1\n",
    "ret_verbose=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks (Configuration and Function Call)\n",
    "#### Important  - ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "#### Others - BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Base Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.BaseLogger(stateful_metrics=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "base_logger_stateful_metrics=None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# TerminateOnNaN\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.TerminateOnNaN()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Proggress Bar Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ProgbarLogger(count_mode='samples', stateful_metrics=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(\n",
    "    count_mode=progbar_logger_count_mode, \n",
    "    stateful_metrics=progbar_logger_stateful_metrics)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# History\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.History()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "history = keras.callbacks.History()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model Checkpoint\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ModelCheckpoint()\n",
    "# ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)#\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# verbose=0\n",
    "# save_best_only=False\n",
    "# save_weights_only=False\n",
    "# mode='auto'\n",
    "# period=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "filepath = model_file\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=1\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_file,\n",
    "    monitor=ck_monitor, \n",
    "    verbose=ck_verbose,\n",
    "    save_best_only=ck_save_best_only, \n",
    "    save_weights_only=ck_save_weights_only, \n",
    "    mode=ck_mode, \n",
    "    period=ck_period)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Early Stopping\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# min_delta=0\n",
    "# patience=0\n",
    "# verbose=0\n",
    "# mode='auto'\n",
    "# baseline=None\n",
    "# restore_best_weights=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "es_patience=5\n",
    "es_verbose=1\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "restore_best_weights=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "\n",
    "ret_early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Learning Rate Scheduler\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.LearningRateScheduler(schedule, verbose=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Tensorboard\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# log_dir='./logs' \n",
    "# histogram_freq=0 \n",
    "# batch_size=32\n",
    "# write_graph=True\n",
    "# write_grads=False\n",
    "# write_images=False \n",
    "# embeddings_freq=0\n",
    "# embeddings_layer_names=None\n",
    "# embeddings_metadata=None\n",
    "# embeddings_data=None\n",
    "# update_freq='epoch'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "tb_log_dir=log_dir\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=tb_log_dir, \n",
    "    histogram_freq=tb_histogram_freq, \n",
    "    batch_size=tb_batch_size,\n",
    "    write_graph=tb_write_graph, \n",
    "    write_grads=tb_write_grads, \n",
    "    write_images=tb_write_images,\n",
    "    embeddings_freq=tb_embeddings_freq,\n",
    "    embeddings_layer_names=tb_embeddings_layer_names, \n",
    "    embeddings_metadata=tb_embeddings_metadata, \n",
    "    embeddings_data=tb_embeddings_data)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# CSV Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "CSV_logger = keras.callbacks.CSVLogger(\n",
    "    CSV_logger_filename, \n",
    "    separator=CSV_logger_separator,\n",
    "    append=CSV_logger_append)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Reduce Learning Rate On Plateau\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# factor=0.1\n",
    "# patience=10\n",
    "# verbose=0\n",
    "# mode='auto'\n",
    "# min_delta=0.0001\n",
    "# cooldown=0\n",
    "# min_lr=0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_factor=0.5\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=red_lr_monitor, \n",
    "    factor=red_lr_factor, \n",
    "    patience=red_lr_patience,\n",
    "    verbose=red_lr_verbose, \n",
    "    mode=red_lr_mode, \n",
    "    min_delta=red_lr_min_delta,\n",
    "    cooldown=red_lr_cooldown,\n",
    "    min_lr=red_lr_min_lr)\n",
    "\n",
    "ret_reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=red_lr_monitor, \n",
    "    factor=red_lr_factor, \n",
    "    patience=red_lr_patience,\n",
    "    verbose=red_lr_verbose, \n",
    "    mode=red_lr_mode, \n",
    "    min_delta=red_lr_min_delta,\n",
    "    cooldown=red_lr_cooldown,\n",
    "    min_lr=red_lr_min_lr)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Callbacks\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# base_logger \n",
    "# terminate_on_NaN \n",
    "# progbar_logger \n",
    "# history \n",
    "# checkpoint \n",
    "# early_stopping\n",
    "# tensorboard \n",
    "# CSV_logger \n",
    "# reduce_lr\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# callbacks = None\n",
    "# callbacks = [checkpoint, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Initial Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_callbacks = None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Main Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Retrain Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "retrain_callbacks = [checkpoint, ret_reduce_lr, ret_early_stopping, tensorboard]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 02:01:04\n",
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 13,215,106\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n",
      "Timestamp: 2018-12-05 02:01:42\n"
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "date_time(1)\n",
    "\n",
    "model = get_inception_model(\n",
    "    train_generator, \n",
    "    validation_generator, \n",
    "    init_epochs, \n",
    "    init_verbose, \n",
    "    init_optimizer, \n",
    "    loss, metrics, \n",
    "    tensorboard, \n",
    "    init_callbacks, \n",
    "    num_class, \n",
    "    include_top, \n",
    "    non_trainable_index, \n",
    "    print_layers)\n",
    "\n",
    "main_model = model\n",
    "\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_report=True\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning with New Class Labels\n",
    "#### Fine-Tuning InceptionV3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 02:01:45\n",
      "Epoch 1/10\n",
      "1032/1032 [==============================] - 7189s 7s/step - loss: 0.2989 - acc: 0.9014 - val_loss: 2.2894 - val_acc: 0.6004\n",
      "\n",
      "Epoch 00001: saving model to data/output/models/2018-12-05 01-57-41/01-val_acc-0.60-val_loss-2.29.hdf5\n",
      "Epoch 2/10\n",
      "1032/1032 [==============================] - 7588s 7s/step - loss: 0.2356 - acc: 0.9236 - val_loss: 1.5974 - val_acc: 0.6352\n",
      "\n",
      "Epoch 00002: saving model to data/output/models/2018-12-05 01-57-41/02-val_acc-0.64-val_loss-1.60.hdf5\n",
      "Epoch 3/10\n",
      "1032/1032 [==============================] - 6359s 6s/step - loss: 0.2137 - acc: 0.9316 - val_loss: 2.1584 - val_acc: 0.6165\n",
      "\n",
      "Epoch 00003: saving model to data/output/models/2018-12-05 01-57-41/03-val_acc-0.62-val_loss-2.16.hdf5\n",
      "Epoch 4/10\n",
      "1032/1032 [==============================] - 5512s 5s/step - loss: 0.2004 - acc: 0.9365 - val_loss: 1.5278 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00004: saving model to data/output/models/2018-12-05 01-57-41/04-val_acc-0.62-val_loss-1.53.hdf5\n",
      "Epoch 5/10\n",
      "1032/1032 [==============================] - 5745s 6s/step - loss: 0.1886 - acc: 0.9390 - val_loss: 2.7698 - val_acc: 0.6009\n",
      "\n",
      "Epoch 00005: saving model to data/output/models/2018-12-05 01-57-41/05-val_acc-0.60-val_loss-2.77.hdf5\n",
      "Epoch 6/10\n",
      "1032/1032 [==============================] - 5528s 5s/step - loss: 0.1789 - acc: 0.9426 - val_loss: 1.3426 - val_acc: 0.6231\n",
      "\n",
      "Epoch 00006: saving model to data/output/models/2018-12-05 01-57-41/06-val_acc-0.62-val_loss-1.34.hdf5\n",
      "Epoch 7/10\n",
      "1032/1032 [==============================] - 5575s 5s/step - loss: 0.1706 - acc: 0.9456 - val_loss: 1.7185 - val_acc: 0.6215\n",
      "\n",
      "Epoch 00007: saving model to data/output/models/2018-12-05 01-57-41/07-val_acc-0.62-val_loss-1.72.hdf5\n",
      "Epoch 8/10\n",
      "1032/1032 [==============================] - 6036s 6s/step - loss: 0.1623 - acc: 0.9476 - val_loss: 2.2186 - val_acc: 0.6033\n",
      "\n",
      "Epoch 00008: saving model to data/output/models/2018-12-05 01-57-41/08-val_acc-0.60-val_loss-2.22.hdf5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/10\n",
      "1032/1032 [==============================] - 6879s 7s/step - loss: 0.1363 - acc: 0.9567 - val_loss: 2.5119 - val_acc: 0.6079\n",
      "\n",
      "Epoch 00009: saving model to data/output/models/2018-12-05 01-57-41/09-val_acc-0.61-val_loss-2.51.hdf5\n",
      "Epoch 10/10\n",
      "1032/1032 [==============================] - 6351s 6s/step - loss: 0.1280 - acc: 0.9596 - val_loss: 2.6067 - val_acc: 0.6129\n",
      "\n",
      "Epoch 00010: saving model to data/output/models/2018-12-05 01-57-41/10-val_acc-0.61-val_loss-2.61.hdf5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Timestamp: 2018-12-05 19:32:40\n"
     ]
    }
   ],
   "source": [
    "date_time(1)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    "\n",
    "date_time(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "\n",
    "plot_property =  {\n",
    "    'figsize':(15, 5),\n",
    "    'title':['Model accuracy', 'Model loss'],\n",
    "    'xlabel':['Epoch', 'Epoch'],\n",
    "    'ylabel':['Accuracy', 'Loss'],\n",
    "    'legend': ['Train', 'Val'],\n",
    "    'title_fontsize' : 17,\n",
    "    'label_fontsize':15, \n",
    "    'subplot':[121, 122]}\n",
    "\n",
    "\n",
    "plot_history(history, plot_val, plot_property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 498s 1s/step\n"
     ]
    }
   ],
   "source": [
    "result  = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6067435538439625\n",
      "61.29303488835951 %\n"
     ]
    }
   ],
   "source": [
    "print(result[0])\n",
    "print(result[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 838s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes=y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 21:54:42\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_3/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@batch_normalization_3/cond/FusedBatchNorm/Switch\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_2/Relu, conv2d_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean/_4021}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3245_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-07bd0fbba242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mreport_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"full\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mresults1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-050d36fc9877>\u001b[0m in \u001b[0;36mtest_all_models\u001b[1;34m(model_dir, details, report_type, classes, class_name)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mcurrent_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0my_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_report_print\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-7578c4a3d570>\u001b[0m in \u001b[0;36mmodel_evaluate\u001b[1;34m(model, test_generator, print_report)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    344\u001b[0m                                  \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                                  str(generator_output))\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_3/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@batch_normalization_3/cond/FusedBatchNorm/Switch\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_2/Relu, conv2d_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean/_4021}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3245_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "date_time(1)\n",
    "\n",
    "details = True\n",
    "class_name = \"Cancer\"\n",
    "\n",
    "report_type = \"full\"\n",
    "results1, results2, report = test_all_models(model_dir, details, report_type, classes, class_name=class_name)\n",
    "\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename_list=[]\n",
    "model_file_path_list=[]\n",
    "for model_filename in results2:\n",
    "    model_filename_list.append(model_filename)\n",
    "    model_file_path_list.append(model_dir+model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_names = ['Normal-precision', 'Normal-recall', 'Normal-f1-score', \n",
    "                     'Cancer-precision','Cancer-recall', 'Cancer-f1-score', \n",
    "                     'micro avg-precision', 'micro avg-recall', 'micro avg-f1-score', \n",
    "                     'macro avg-precision', 'macro avg-recall', 'macro avg-f1-score', \n",
    "                     'weighted avg-precision', 'weighted avg-recall', 'weighted avg-f1-score',\n",
    "                     'Accuracy', 'Loss']\n",
    "metric_array_list=[]\n",
    "\n",
    "\n",
    "# 0\n",
    "negative_precision_list = [results2[i][1]['Normal']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_precision_list)\n",
    "\n",
    "# 1\n",
    "negative_recall_list = [results2[i][1]['Normal']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_recall_list)\n",
    "\n",
    "# 2\n",
    "negative_f1_score_list = [results2[i][1]['Normal']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "# 3\n",
    "positive_precision_list = [results2[i][1]['Cancer']['precision'] for i in results2]\n",
    "metric_array_list.append(positive_precision_list)\n",
    "\n",
    "# 4\n",
    "positive_recall_list = [results2[i][1]['Cancer']['recall'] for i in results2]\n",
    "metric_array_list.append(positive_recall_list)\n",
    "\n",
    "# 5\n",
    "positive_f1_score_list = [results2[i][1]['Cancer']['f1-score'] for i in results2]\n",
    "metric_array_list.append(positive_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 6\n",
    "micro_precision_list = [results2[i][1]['micro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(micro_precision_list)\n",
    "\n",
    "# 7\n",
    "micro_recall_list = [results2[i][1]['micro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(micro_recall_list)\n",
    "\n",
    "# 8\n",
    "micro_f1_score_list = [results2[i][1]['micro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(micro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 9\n",
    "macro_precision_list = [results2[i][1]['macro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(macro_precision_list)\n",
    "\n",
    "# 10\n",
    "macro_recall_list = [results2[i][1]['macro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(macro_recall_list)\n",
    "\n",
    "# 11\n",
    "macro_f1_score_list = [results2[i][1]['macro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(macro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 12\n",
    "weighted_precision_list = [results2[i][1]['weighted avg']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 13\n",
    "weighted_recall_list = [results2[i][1]['weighted avg']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 14\n",
    "weighted_f1_score_list = [results2[i][1]['weighted avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 15\n",
    "accuracy_list = [results1[i][0] for i in results1]\n",
    "metric_array_list.append(accuracy_list)\n",
    "\n",
    "# 16\n",
    "loss_list = [results1[i][1]for i in results1]\n",
    "metric_array_list.append(loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_list_percent = metric_array_list\n",
    "num_metrics = len(metric_array_list)\n",
    "for i in range(num_metrics):\n",
    "    if i!=16:\n",
    "        metric_array_list_percent[i] = [i*100 for i in metric_array_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_array_list_norm = metric_array_list\n",
    "# for i in range(len(metric_array_list)):\n",
    "#     m=max(metric_array_list[i])\n",
    "#     metric_array_list_norm[i] = [i/m for i in metric_array_list_norm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_index = [1,2,7,8,10,11]\n",
    "plot_index = [2, 3,4,5, 12, 13, 14, 15]\n",
    "\n",
    "# plot_index = [2, 3,4,5, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col = 12\n",
    "figsize_row = 4\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'Large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_plot = False\n",
    "# seperate_plot = True\n",
    "\n",
    "filter_skip = False\n",
    "\n",
    "filter_plot = False\n",
    "filter_plot = True\n",
    "\n",
    "dpi=150\n",
    "\n",
    "\n",
    "length=len(metric_array_list)\n",
    "num_epochs=len(results2)\n",
    "x = np.arange(num_epochs)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(18, 12), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "for i in range(length):\n",
    "    if not filter_plot or i in plot_index:\n",
    "        if seperate_plot:  \n",
    "            fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "            plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "            \n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Score (100%)\")\n",
    "#             plt.yticks(np.arange(0, 100, 5))\n",
    "#             plt.xticks(np.arange(0, num_epochs, 1))\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "#             plt.ylim([min(metric_array_list_percent[i]),max(metric_array_list_percent[i])])\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "        \n",
    "\n",
    "            \n",
    "if not seperate_plot:\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Val\")\n",
    "#     plt.yticks(np.arange(0, 100, 5))\n",
    "#     plt.xticks(np.arange(0, num_epochs, 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col=10\n",
    "figsize_row=3\n",
    "fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "\n",
    "\n",
    "x = np.arange(len(results1))\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x, accuracy_list, label=\"Accuarcy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score(100%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x, loss_list, label= \"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [3,13,17, 18]\n",
    "num_model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metric_array_list_percent)):\n",
    "    print(\"%6s%10s%.2f\"%(metric_array_names[i],\":\", metric_array_list_percent[i][num_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir=\"data\\\\output\\\\models\\\\20181201035451\\\\\"\n",
    "# model=keras.models.load_model(model_dir+\"30-val_acc-0.85-val_loss-0.66.hdf5\")\n",
    "\n",
    "model_path = model_file_path_list[num_model]\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report=True)\n",
    "y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Normal', 'PNEUMONIA']\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM , figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
