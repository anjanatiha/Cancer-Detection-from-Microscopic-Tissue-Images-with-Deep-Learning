{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Histopathologic Cancer Detection using Convolutional Neural Network, and Transfer Learning.\n",
    "Description      : 1. Detected Cancer from Histopathologic images by retraining pretrained model “InceptionV3” with                            250000+ images of X-ray (6GB).\n",
    "                   2. For retraining, removed output layers, freezed first few layers and Fine-tuned model for two new label                   classes (Cancer and Normal).\n",
    "                   3. Attained testing accuracy 69.55 and loss 1.10.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.28.2018\n",
    "Comments         : Please use Anaconda editor for convenience.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Histopathologic Cancer Detection\n",
    "Dataset Link     : <a href=https://www.kaggle.com/c/histopathologic-cancer-detection>Histopathologic Cancer Detection (Kaggle)</a>\n",
    "                 : <a href=https://github.com/basveeling/pcam> PatchCamelyon (PCam) (GitHub)</a>\n",
    "                 : <a href=https://camelyon16.grand-challenge.org/Data>CAMELYON16 challenge Dataset (Original Dataset)</a>\n",
    "                 \n",
    "Original Paper   : <a href=https://jamanetwork.com/journals/jama/fullarticle/2665774>Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer</a> \n",
    "                   Authors: Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes van Diest \n",
    "                   JAMA (The Journal of the American Medical Association)\n",
    "                   <cite>\n",
    "                   Ehteshami Bejnordi B, Veta M, Johannes van Diest P, et al. Diagnostic Assessment of Deep Learning                        Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA.                                     2017;318(22):2199–2210. doi:10.1001/jama.2017.14585\n",
    "                   </cite>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Histopathologic Cancer Detection\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 220,025 (5.72 Gigabyte (GB))\n",
    "                          Training   : 132,016 (3.43 Gigabyte (GB))\n",
    "                          Validation : 44,005  (1.14 Gigabyte (GB))\n",
    "                          Testing    : 44,004  (1.14 Gigabyte (GB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 32\n",
    "Number of Epochs        : 20\n",
    "Training Time           : 1 day and 8 hour (33 Hours)\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 69.55%\n",
    "Loss                    : 1.10\n",
    "<!--Precision               : -->\n",
    "Recall                  : \n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Deletes file, if file exists \n",
    "def remove_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except:\n",
    "            print(\"Could not remove file : \", filename)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time for given type of representation\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "               \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "\n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(\n",
    "        x,\n",
    "        y, \n",
    "        title, \n",
    "        xlabel, \n",
    "        ylabel, \n",
    "        figsize=fig_size, \n",
    "        title_fontsize=title_fontsize, \n",
    "        label_fontsize=label_fontsize, \n",
    "        subplot_no=subplot_no)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    count_bar_plot(\n",
    "        training_dir, \n",
    "        title +\" (Training)\", \n",
    "        xlabel, \n",
    "        ylabel, \n",
    "        fig_size, \n",
    "        title_fontsize, \n",
    "        label_fontsize, \n",
    "        subplot_no=131)\n",
    "    \n",
    "    count_bar_plot(\n",
    "        validation_dir, \n",
    "        title +\" (Validation)\",\n",
    "        xlabel, \n",
    "        ylabel, \n",
    "        fig_size,\n",
    "        title_fontsize, \n",
    "        label_fontsize, \n",
    "        subplot_no=132)\n",
    "    \n",
    "    count_bar_plot(\n",
    "        testing_dir, \n",
    "        title +\" (Testing)\",\n",
    "        xlabel, \n",
    "        ylabel, \n",
    "        fig_size,\n",
    "        title_fontsize,\n",
    "        label_fontsize, \n",
    "        subplot_no=133)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, target_size, classes, class_mode='categorical', batch_size=1, shuffle=True, rescale=None, shear_range=0.0, zoom_range=0.0, horizontal_flip=False, validation_split=0.0):       \n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=rescale,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip,\n",
    "        validation_split=validation_split)     \n",
    "    \n",
    "    image_generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=target_size,\n",
    "        classes = classes,\n",
    "        class_mode=class_mode,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, optimizer, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        # compile model with loss, optimizer and metrics \n",
    "        model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "        # train the model on the new data for a few epochs\n",
    "        model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = len(train_generator),\n",
    "            epochs=epochs,\n",
    "            # verbose=verbose, \n",
    "            callbacks=callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=len(validation_generator),\n",
    "            class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    if not callbacks:\n",
    "        model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "        \n",
    "        tensorboard.set_model(model) \n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, title, xlabel, ylabel, legend=[['Train', 'Val'], ['Train', 'Val']], fig_size=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    plt.title(title[0], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[0], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[0], fontsize=label_fontsize)\n",
    "    plt.legend(legend[0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    plt.title(title[1], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[1], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[1], fontsize=label_fontsize)\n",
    "    plt.legend(legend[1], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "        \n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "    \n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    \n",
    "    cls_report_print = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    \n",
    "    cls_report = classification_report(test_generator.classes, y_classes, target_names=classes, output_dict=True)\n",
    "    \n",
    "    if print_report: \n",
    "        print(cls_report_print)\n",
    "        \n",
    "    return y_preds, y_classes, CM, cls_report, cls_report_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    \n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "        \n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, title, xlabel=\"Epoch\", ylabel=\"Value\", title_fontsize=14, label_fontsize=12, subplot_no=0):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    \n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "        \n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, title, fig_size=(10, 8), xlabel=[\"Epoch\", \"Epoch\"], ylabel=[\"Value\",\"Value\"], title_fontsize=14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    line_plot_over_epochs(\n",
    "        array[0], \n",
    "        title[0], \n",
    "        xlabel=xlabel[0], \n",
    "        ylabel=ylabel[0], \n",
    "        title_fontsize=title_fontsize, \n",
    "        label_fontsize=label_fontsize, \n",
    "        subplot_no=121)\n",
    "    \n",
    "    \n",
    "    line_plot_over_epochs(\n",
    "        array[1], \n",
    "        title[1], \n",
    "        xlabel=xlabel[1], \n",
    "        ylabel=ylabel[1], \n",
    "        title_fontsize=title_fontsize, \n",
    "        label_fontsize=label_fontsize, \n",
    "        subplot_no=122)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    \n",
    "    fig, ax = plot_confusion_matrix(\n",
    "        conf_mat=CM ,  \n",
    "        figsize=figsize, \n",
    "        hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    \n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_filename, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "        \n",
    "    model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "    if not os.path.isdir(model_path):\n",
    "        return None\n",
    "    \n",
    "    reset_graph(model)\n",
    "\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    accuracy, loss =  model_evaluate(\n",
    "        model, \n",
    "        test_generator, \n",
    "        print_report=False)\n",
    "    \n",
    "    y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "\n",
    "    precision = cls_report[class_name]['precision'] *100\n",
    "    recall =  cls_report[class_name]['recall'] *100\n",
    "    f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "\n",
    "\n",
    "\n",
    "    results1[model_filename] = [accuracy, loss]\n",
    "    results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "    print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "    print(\"*\"*80)\n",
    "    show_confusion_matrix(test_generator, y_classes, classes)\n",
    "    print(cls_report_print)\n",
    "    print(\"%s%.2f%s\"% (\"Current Accuracy: \", accuracy, \"%\"))\n",
    "    print(\"%s%.2f\"% (\"Current Loss: \", loss))\n",
    "    print(\"%s%.2f%s\"% (\"Current Precision: \", precision, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current Recall: \", recall, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current F1_score: \", f1_score, \"%\"))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    \n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "\n",
    "    report = {\"Accuracy\" : accuracy, \n",
    "              \"Loss\" : loss,\n",
    "              \"Precision\" : precision,\n",
    "              \"Recall\": recall,\n",
    "              \"F1-Score\":f1_score}\n",
    "\n",
    "\n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    filenames=[]\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    loss_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    \n",
    "    \n",
    "    best_accuracy=0\n",
    "    best_accuracy_file=\"\"\n",
    "    \n",
    "    best_loss=1000\n",
    "    best_loss_file=\"\"\n",
    "    \n",
    "    \n",
    "    best_precision=0\n",
    "    best_precision_file=\"\"\n",
    "    \n",
    "    best_recall=0\n",
    "    best_recall_file=\"\"\n",
    "    \n",
    "    best_f1_score=0\n",
    "    best_f1_score_file=\"\"\n",
    "    \n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    model = None\n",
    "    reset_graph(model)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for model_filename in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "            \n",
    "            current_accuracy, current_loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "            y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "            \n",
    "            current_precision = cls_report[class_name]['precision'] *100\n",
    "            current_recall =  cls_report[class_name]['recall'] *100\n",
    "            current_f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "            \n",
    "            filenames.append(model_file)\n",
    "            \n",
    "            accuracy_list.append(current_accuracy)\n",
    "            loss_list.append(current_loss)\n",
    "            \n",
    "            precision_list.append(current_precision)\n",
    "            recall_list.append(current_recall)\n",
    "            f1_score_list.append(current_f1_score)\n",
    "            \n",
    "            \n",
    "            results1[model_filename] = [current_accuracy, current_loss]\n",
    "            results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "                \n",
    "            if current_accuracy>=best_accuracy:\n",
    "                best_accuracy=current_accuracy\n",
    "                best_accuracy_file=model_filename\n",
    "\n",
    "            if current_loss<=best_loss:\n",
    "                best_loss=current_loss\n",
    "                best_loss_file=model_filename\n",
    "                \n",
    "            \n",
    "            if current_precision>=best_precision:\n",
    "                best_precision=current_precision\n",
    "                best_precision_file=model_filename\n",
    "\n",
    "            if current_recall>=best_recall:\n",
    "                best_recall=current_recall\n",
    "                best_recall_file=model_filename\n",
    "                \n",
    "            if current_f1_score>=best_f1_score:\n",
    "                best_f1_score=current_f1_score\n",
    "                best_f1_score_file=model_filename\n",
    "                    \n",
    "\n",
    "            if details or i%5==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "                print(\"*\"*80)\n",
    "                show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                print(cls_report_print)\n",
    "                print(\"%s%.2f%s\"% (\"Current Accuracy: \", current_accuracy, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Current Loss: \", current_loss))\n",
    "                print(\"%s%.2f%s\"% (\"Current Precision: \", current_precision, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current Recall: \", current_recall, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current F1_score: \", current_f1_score, \"%\"))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "    \n",
    "    report = {\"Best Accuracy\" : [best_accuracy, best_accuracy_file], \n",
    "                   \"Best Loss\" : [best_loss, best_loss_file],\n",
    "                   \"Best Precision\" : [best_precision, best_precision_file],\n",
    "                   \"Best Recall\": [best_recall, best_recall_file],\n",
    "                   \"Best F1-Score\":[best_f1_score, best_f1_score_file]}\n",
    "    \n",
    "    \n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 01:57:08\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-23dd3853590a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mreset_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "date_time(x)\n",
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train_final\"\n",
    "testing_dir = input_directory+ r\"test_final\"\n",
    "validation_dir = input_directory+ r\"validation_final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_size = (18,4)\n",
    "# fig_size = (4,2)\n",
    "\n",
    "# title_fontsize=14\n",
    "title_fontsize=13\n",
    "label_fontsize=13\n",
    "# label_fontsize=12\n",
    "\n",
    "title=\"Number of Cases\"\n",
    "\n",
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "\n",
    "\n",
    "show_train_val_test(\n",
    "    training_dir, \n",
    "    validation_dir, \n",
    "    testing_dir,\n",
    "    title,\n",
    "    xlabel, \n",
    "    ylabel, \n",
    "    figsize=fig_size, \n",
    "    title_fontsize = title_fontsize,\n",
    "    label_fontsize=label_fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of labels/classes/categories\n",
    "#------------------------------------------------#\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "#------------------------------------------------#\n",
    "\n",
    "# Image normalization\n",
    "#----------------------#\n",
    "norm=255.0\n",
    "\n",
    "# recscaling\n",
    "#----------------------#\n",
    "rescale=1./norm\n",
    "\n",
    "# Image Augmentation\n",
    "#----------------------#\n",
    "shear_range=0.2\n",
    "# shear_range=0.1\n",
    "\n",
    "zoom_range=0.2\n",
    "# zoom_range=0.1\n",
    "\n",
    "horizontal_flip=True\n",
    "\n",
    "\n",
    "\n",
    "# Target Image dimention after Image Processing\n",
    "#------------------------------------------------#\n",
    "# default expected image dimension for inceptionv3\n",
    "target_size=(299, 299) \n",
    "# target_size=(224, 224) # used previously\n",
    "\n",
    "\n",
    "# Batch Size for trainning, validation and testing\n",
    "#------------------------------------------------#\n",
    "# Trainning batch size\n",
    "#----------------------#\n",
    "# batch_size=32\n",
    "# batch_size=64\n",
    "batch_size=128\n",
    "\n",
    "# Validation batch size\n",
    "#----------------------#\n",
    "validation_batch_size=batch_size\n",
    "# validation_batch_size=1\n",
    "\n",
    "# Testing batch size\n",
    "#----------------------#\n",
    "test_batch_size=batch_size\n",
    "# test_batch_size=1\n",
    "\n",
    "\n",
    "\n",
    "# Shuffling for testing\n",
    "#------------------------------------------------#\n",
    "test_shuffle=False\n",
    "\n",
    "# Validation split for train, validation dataset\n",
    "#------------------------------------------------#\n",
    "validation_split=0.0\n",
    "\n",
    "# Class mode\n",
    "#------------------------------------------------#\n",
    "# class_mode='binary'\n",
    "class_mode='categorical'\n",
    "# class_mode='sparse'\n",
    "\n",
    "# Classes\n",
    "#------------------------------------------------#\n",
    "classes = ['Normal', 'Cancer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132016 images belonging to 2 classes.\n",
      "Found 44005 images belonging to 2 classes.\n",
      "Found 44005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(\n",
    "    training_dir, \n",
    "    target_size, \n",
    "    classes, \n",
    "    class_mode=class_mode, \n",
    "    batch_size=batch_size, \n",
    "    rescale=rescale, \n",
    "    shear_range=shear_range, \n",
    "    zoom_range=zoom_range, \n",
    "    horizontal_flip=horizontal_flip)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(\n",
    "    validation_dir, \n",
    "    target_size,\n",
    "    classes, \n",
    "    class_mode=class_mode,\n",
    "    batch_size=validation_batch_size,\n",
    "    rescale=rescale)       \n",
    "\n",
    "test_generator = get_transformed_image_batch(\n",
    "    validation_dir, \n",
    "    target_size, \n",
    "    classes, \n",
    "    class_mode=class_mode, \n",
    "    batch_size=test_batch_size,\n",
    "    shuffle = test_shuffle,\n",
    "    rescale=rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Adjustment for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "# class_weight=None\n",
    "# class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Configuration\n",
    "### Setting Output Directory (Model and Log) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model Directory\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "model_dir=output_directory + r\"models/\"+time.strftime('%Y-%m-%d %H-%M-%S')+\"/\"\n",
    "# model_dir=output_directory + r\"models/\"+time.strftime('%Y%m%d%H%M%S')+\"/\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Log Directory\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# log_dir=output_directory + r\"logs/\"+time.strftime('%Y%m%d%H%M%S')\n",
    "log_dir=output_directory + r\"logs/\"+time.strftime('%Y-%m-%d %H-%M-%S')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "# Create Output Directory (Model and Log)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model File Name Configuration\n",
    "#------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Initial Trainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "init_model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Trainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "model_file=model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Retrainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "retrain_model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape=(3,150,150)\n",
    "input_shape=(3,299,299)\n",
    "\n",
    "activation='relu'\n",
    "# activation2='sigmoid'\n",
    "activation2='softmax'\n",
    "\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "\n",
    "pool_size=(2, 2)\n",
    "\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Configuration\n",
    "\n",
    "#### Base Model - InceptionV3 (pretrained) initial training settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception base top layer discarded\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "non_trainable_index = 249\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_optimizer=optimizers.Adam()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# init_epochs=1\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "print_layers=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning Parameters\n",
    "##### Settings for Loss, Optimizer and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "# Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "# Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "# Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "# Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.optimizers.X\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# learning rate = 1.0/0.1/0.01/0.001/0.0001/0.00001/0.000001\n",
    "# Decay = decay=1e-5/ 1e-6\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_optimizer=optimizers.Adam()\n",
    "optimizer=optimizers.Adam()\n",
    "ret_optimizer=optimizers.Adam()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# loss Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Loss Functions\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error',\n",
    "# 'squared_hinge', 'hinge', 'categorical_hinge', 'logcosh',\n",
    "# 'categorical_crossentropy', 'sparse_categorical_crossentropy', 'binary_crossentropy',\n",
    "# 'kullback_leibler_divergence', 'poisson', 'cosine_proximity'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.loss.X ??\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_loss='categorical_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "ret_loss='categorical_crossentropy'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Performance Metrics\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Metrics\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 'binary_accuracy', 'categorical_accuracy', 'sparse_categorical_accuracy', \n",
    "# 'top_k_categorical_accuracy', 'sparse_top_k_categorical_accuracy\n",
    "# None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.metrics.X\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_metrics=['accuracy']\n",
    "metrics=['accuracy']\n",
    "ret_metrics=['accuracy']\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_pred(y_true, y_pred):\n",
    "#     return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Parameters (Epochs, Steps, Verbose)\n",
    "#### Main model training parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Epochs\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# epochs = 10/20/30/50\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Number of Epochs\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_epochs = 10\n",
    "epochs = 10\n",
    "ret_epochs = 10\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Trainning Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "# steps_per_epoch=60/600\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Steps Per Epoch\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_steps_per_epoch=len(train_generator)\n",
    "steps_per_epoch=len(train_generator)\n",
    "ret_steps_per_epoch=len(train_generator)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Validation Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# validation_steps=1/20/200\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Validation Per Epoch\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_validation_steps=len(validation_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "ret_validation_steps=len(validation_generator)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 0=nothing \n",
    "# 1=each line\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_verbose=1\n",
    "verbose=1\n",
    "ret_verbose=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks (Configuration and Function Call)\n",
    "#### Important  - ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "#### Others - BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Base Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.BaseLogger(stateful_metrics=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "base_logger_stateful_metrics=None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# TerminateOnNaN\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.TerminateOnNaN()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Proggress Bar Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ProgbarLogger(count_mode='samples', stateful_metrics=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(\n",
    "    count_mode=progbar_logger_count_mode, \n",
    "    stateful_metrics=progbar_logger_stateful_metrics)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# History\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.History()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "history = keras.callbacks.History()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model Checkpoint\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ModelCheckpoint()\n",
    "# ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)#\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# verbose=0\n",
    "# save_best_only=False\n",
    "# save_weights_only=False\n",
    "# mode='auto'\n",
    "# period=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "filepath = model_file\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=1\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_file,\n",
    "    monitor=ck_monitor, \n",
    "    verbose=ck_verbose,\n",
    "    save_best_only=ck_save_best_only, \n",
    "    save_weights_only=ck_save_weights_only, \n",
    "    mode=ck_mode, \n",
    "    period=ck_period)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Early Stopping\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# min_delta=0\n",
    "# patience=0\n",
    "# verbose=0\n",
    "# mode='auto'\n",
    "# baseline=None\n",
    "# restore_best_weights=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "es_patience=5\n",
    "es_verbose=1\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "restore_best_weights=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "\n",
    "ret_early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Learning Rate Scheduler\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.LearningRateScheduler(schedule, verbose=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Tensorboard\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# log_dir='./logs' \n",
    "# histogram_freq=0 \n",
    "# batch_size=32\n",
    "# write_graph=True\n",
    "# write_grads=False\n",
    "# write_images=False \n",
    "# embeddings_freq=0\n",
    "# embeddings_layer_names=None\n",
    "# embeddings_metadata=None\n",
    "# embeddings_data=None\n",
    "# update_freq='epoch'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "tb_log_dir=log_dir\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=tb_log_dir, \n",
    "    histogram_freq=tb_histogram_freq, \n",
    "    batch_size=tb_batch_size,\n",
    "    write_graph=tb_write_graph, \n",
    "    write_grads=tb_write_grads, \n",
    "    write_images=tb_write_images,\n",
    "    embeddings_freq=tb_embeddings_freq,\n",
    "    embeddings_layer_names=tb_embeddings_layer_names, \n",
    "    embeddings_metadata=tb_embeddings_metadata, \n",
    "    embeddings_data=tb_embeddings_data)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# CSV Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "CSV_logger = keras.callbacks.CSVLogger(\n",
    "    CSV_logger_filename, \n",
    "    separator=CSV_logger_separator,\n",
    "    append=CSV_logger_append)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Reduce Learning Rate On Plateau\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# factor=0.1\n",
    "# patience=10\n",
    "# verbose=0\n",
    "# mode='auto'\n",
    "# min_delta=0.0001\n",
    "# cooldown=0\n",
    "# min_lr=0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_factor=0.5\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=red_lr_monitor, \n",
    "    factor=red_lr_factor, \n",
    "    patience=red_lr_patience,\n",
    "    verbose=red_lr_verbose, \n",
    "    mode=red_lr_mode, \n",
    "    min_delta=red_lr_min_delta,\n",
    "    cooldown=red_lr_cooldown,\n",
    "    min_lr=red_lr_min_lr)\n",
    "\n",
    "ret_reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=red_lr_monitor, \n",
    "    factor=red_lr_factor, \n",
    "    patience=red_lr_patience,\n",
    "    verbose=red_lr_verbose, \n",
    "    mode=red_lr_mode, \n",
    "    min_delta=red_lr_min_delta,\n",
    "    cooldown=red_lr_cooldown,\n",
    "    min_lr=red_lr_min_lr)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Callbacks\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# base_logger \n",
    "# terminate_on_NaN \n",
    "# progbar_logger \n",
    "# history \n",
    "# checkpoint \n",
    "# early_stopping\n",
    "# tensorboard \n",
    "# CSV_logger \n",
    "# reduce_lr\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# callbacks = None\n",
    "# callbacks = [checkpoint, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Initial Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_callbacks = None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Main Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Retrain Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "retrain_callbacks = [checkpoint, ret_reduce_lr, ret_early_stopping, tensorboard]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 02:01:04\n",
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 13,215,106\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n",
      "Timestamp: 2018-12-05 02:01:42\n"
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "date_time(1)\n",
    "\n",
    "model = get_inception_model(\n",
    "    train_generator, \n",
    "    validation_generator, \n",
    "    init_epochs, \n",
    "    init_verbose, \n",
    "    init_optimizer, \n",
    "    loss, metrics, \n",
    "    tensorboard, \n",
    "    init_callbacks, \n",
    "    num_class, \n",
    "    include_top, \n",
    "    non_trainable_index, \n",
    "    print_layers)\n",
    "\n",
    "main_model = model\n",
    "\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_report=True\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning with New Class Labels\n",
    "#### Fine-Tuning InceptionV3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 02:01:45\n",
      "Epoch 1/10\n",
      "  28/1032 [..............................] - ETA: 1:42:53 - loss: 0.7434 - acc: 0.7787"
     ]
    }
   ],
   "source": [
    "date_time(1)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    "\n",
    "date_time(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "title = ['Model accuracy', 'Model loss']\n",
    "\n",
    "xlabel = ['Epoch', 'Epoch']\n",
    "ylabel = ['Accuracy', 'Loss']\n",
    "\n",
    "legend = ['Train', 'Val']\n",
    "\n",
    "fig_size=(15, 5)\n",
    "\n",
    "\n",
    "title_fontsize=17\n",
    "label_fontsize=15\n",
    "\n",
    "plot_history(history, \n",
    "             plot_val, \n",
    "             title, \n",
    "             xlabel, \n",
    "             ylabel, \n",
    "             fig_size=fig_size, \n",
    "             title_fontsize=title_fontsize, \n",
    "             label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result  = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0])\n",
    "print(result[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes=y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time(1)\n",
    "\n",
    "details = True\n",
    "class_name = \"Cancer\"\n",
    "\n",
    "report_type = \"full\"\n",
    "results1, results2, report = test_all_models(model_dir, details, report_type, classes, class_name=class_name)\n",
    "\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename_list=[]\n",
    "model_file_path_list=[]\n",
    "for model_filename in results2:\n",
    "    model_filename_list.append(model_filename)\n",
    "    model_file_path_list.append(model_dir+model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_names = ['Normal-precision', 'Normal-recall', 'Normal-f1-score', \n",
    "                     'Cancer-precision','Cancer-recall', 'Cancer-f1-score', \n",
    "                     'micro avg-precision', 'micro avg-recall', 'micro avg-f1-score', \n",
    "                     'macro avg-precision', 'macro avg-recall', 'macro avg-f1-score', \n",
    "                     'weighted avg-precision', 'weighted avg-recall', 'weighted avg-f1-score',\n",
    "                     'Accuracy', 'Loss']\n",
    "metric_array_list=[]\n",
    "\n",
    "\n",
    "# 0\n",
    "negative_precision_list = [results2[i][1]['Normal']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_precision_list)\n",
    "\n",
    "# 1\n",
    "negative_recall_list = [results2[i][1]['Normal']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_recall_list)\n",
    "\n",
    "# 2\n",
    "negative_f1_score_list = [results2[i][1]['Normal']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "# 3\n",
    "positive_precision_list = [results2[i][1]['Cancer']['precision'] for i in results2]\n",
    "metric_array_list.append(positive_precision_list)\n",
    "\n",
    "# 4\n",
    "positive_recall_list = [results2[i][1]['Cancer']['recall'] for i in results2]\n",
    "metric_array_list.append(positive_recall_list)\n",
    "\n",
    "# 5\n",
    "positive_f1_score_list = [results2[i][1]['Cancer']['f1-score'] for i in results2]\n",
    "metric_array_list.append(positive_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 6\n",
    "micro_precision_list = [results2[i][1]['micro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(micro_precision_list)\n",
    "\n",
    "# 7\n",
    "micro_recall_list = [results2[i][1]['micro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(micro_recall_list)\n",
    "\n",
    "# 8\n",
    "micro_f1_score_list = [results2[i][1]['micro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(micro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 9\n",
    "macro_precision_list = [results2[i][1]['macro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(macro_precision_list)\n",
    "\n",
    "# 10\n",
    "macro_recall_list = [results2[i][1]['macro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(macro_recall_list)\n",
    "\n",
    "# 11\n",
    "macro_f1_score_list = [results2[i][1]['macro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(macro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 12\n",
    "weighted_precision_list = [results2[i][1]['weighted avg']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 13\n",
    "weighted_recall_list = [results2[i][1]['weighted avg']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 14\n",
    "weighted_f1_score_list = [results2[i][1]['weighted avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 15\n",
    "accuracy_list = [results1[i][0] for i in results1]\n",
    "metric_array_list.append(accuracy_list)\n",
    "\n",
    "# 16\n",
    "loss_list = [results1[i][1]for i in results1]\n",
    "metric_array_list.append(loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_list_percent = metric_array_list\n",
    "num_metrics = len(metric_array_list)\n",
    "for i in range(num_metrics):\n",
    "    if i!=16:\n",
    "        metric_array_list_percent[i] = [i*100 for i in metric_array_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_array_list_norm = metric_array_list\n",
    "# for i in range(len(metric_array_list)):\n",
    "#     m=max(metric_array_list[i])\n",
    "#     metric_array_list_norm[i] = [i/m for i in metric_array_list_norm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_index = [1,2,7,8,10,11]\n",
    "plot_index = [2, 3,4,5, 12, 13, 14, 15]\n",
    "\n",
    "# plot_index = [2, 3,4,5, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col = 12\n",
    "figsize_row = 4\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'Large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_plot = False\n",
    "# seperate_plot = True\n",
    "\n",
    "filter_skip = False\n",
    "\n",
    "filter_plot = False\n",
    "filter_plot = True\n",
    "\n",
    "dpi=150\n",
    "\n",
    "\n",
    "length=len(metric_array_list)\n",
    "num_epochs=len(results2)\n",
    "x = np.arange(num_epochs)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(18, 12), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "for i in range(length):\n",
    "    if not filter_plot or i in plot_index:\n",
    "        if seperate_plot:  \n",
    "            fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "            plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "            \n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Score (100%)\")\n",
    "#             plt.yticks(np.arange(0, 100, 5))\n",
    "#             plt.xticks(np.arange(0, num_epochs, 1))\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "#             plt.ylim([min(metric_array_list_percent[i]),max(metric_array_list_percent[i])])\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "        \n",
    "\n",
    "            \n",
    "if not seperate_plot:\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Val\")\n",
    "#     plt.yticks(np.arange(0, 100, 5))\n",
    "#     plt.xticks(np.arange(0, num_epochs, 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col=10\n",
    "figsize_row=3\n",
    "fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "\n",
    "\n",
    "x = np.arange(len(results1))\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x, accuracy_list, label=\"Accuarcy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score(100%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x, loss_list, label= \"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [3,13,17, 18]\n",
    "num_model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metric_array_list_percent)):\n",
    "    print(\"%6s%10s%.2f\"%(metric_array_names[i],\":\", metric_array_list_percent[i][num_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir=\"data\\\\output\\\\models\\\\20181201035451\\\\\"\n",
    "# model=keras.models.load_model(model_dir+\"30-val_acc-0.85-val_loss-0.66.hdf5\")\n",
    "\n",
    "model_path = model_file_path_list[num_model]\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report=True)\n",
    "y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Normal', 'PNEUMONIA']\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM , figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
