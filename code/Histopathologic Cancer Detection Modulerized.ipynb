{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Histopathologic Cancer Detection using Convolutional Neural Network, and Transfer Learning.\n",
    "Description      : 1. Detected Cancer from Histopathologic images by retraining pretrained model “InceptionV3” with                            250000+ images of X-ray (6GB).\n",
    "                   2. For retraining, removed output layers, freezed first few layers and Fine-tuned model for two new label                   classes (Cancer and Normal).\n",
    "                   3. Attained testing accuracy 69.55 and loss 1.10.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.28.2018\n",
    "Comments         : Please use Anaconda editor for convenience.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Histopathologic Cancer Detection\n",
    "Dataset Link     : <a href=https://www.kaggle.com/c/histopathologic-cancer-detection>Histopathologic Cancer Detection (Kaggle)</a>\n",
    "                 : <a href=https://github.com/basveeling/pcam> PatchCamelyon (PCam) (GitHub)</a>\n",
    "                 : <a href=https://camelyon16.grand-challenge.org/Data>CAMELYON16 challenge Dataset (Original Dataset)</a>\n",
    "                 \n",
    "Original Paper   : <a href=https://jamanetwork.com/journals/jama/fullarticle/2665774>Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer</a> \n",
    "                   Authors: Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes van Diest \n",
    "                   JAMA (The Journal of the American Medical Association)\n",
    "                   <cite>\n",
    "                   Ehteshami Bejnordi B, Veta M, Johannes van Diest P, et al. Diagnostic Assessment of Deep Learning                        Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA.                                     2017;318(22):2199–2210. doi:10.1001/jama.2017.14585\n",
    "                   </cite>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Histopathologic Cancer Detection\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 220,025 (5.72 Gigabyte (GB))\n",
    "                          Training   : 132,016 (3.43 Gigabyte (GB))\n",
    "                          Validation : 44,005  (1.14 Gigabyte (GB))\n",
    "                          Testing    : 44,004  (1.14 Gigabyte (GB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 32\n",
    "Number of Epochs        : 20\n",
    "Training Time           : 1 day and 8 hour (33 Hours)\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 69.55%\n",
    "Loss                    : 1.10\n",
    "<!--Precision               : -->\n",
    "Recall                  : \n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Deletes file, if file exists \n",
    "def remove_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except:\n",
    "            print(\"Could not remove file : \", filename)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time for given type of representation\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "               \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "\n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, title, xlabel, ylabel, figsize=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=subplot_no)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    count_bar_plot(training_dir, title +\" (Training)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=131)\n",
    "    count_bar_plot(validation_dir, title +\" (Validation)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=132)\n",
    "    count_bar_plot(testing_dir, title +\" (Testing)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=133)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, target_size, classes, class_mode='categorical', batch_size=1, shuffle=True, rescale=None, shear_range=0.0, zoom_range=0.0, horizontal_flip=False, validation_split=0.0):       \n",
    "    datagen = ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            validation_split=validation_split)     \n",
    "    \n",
    "    image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=target_size,\n",
    "            classes = classes,\n",
    "            class_mode=class_mode,\n",
    "            batch_size=batch_size)\n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, optimizer, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        # compile model with loss, optimizer and metrics \n",
    "        model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "        # train the model on the new data for a few epochs\n",
    "        model.fit_generator(train_generator,\n",
    "                            steps_per_epoch = len(train_generator),\n",
    "                            epochs=epochs,\n",
    "                            # verbose=verbose, \n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=len(validation_generator),\n",
    "                            class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    if not callbacks:\n",
    "        model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "        tensorboard.set_model(model) \n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, title, xlabel, ylabel, legend=[['Train', 'Val'], ['Train', 'Val']], fig_size=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    plt.title(title[0], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[0], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[0], fontsize=label_fontsize)\n",
    "    plt.legend(legend[0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    plt.title(title[1], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[1], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[1], fontsize=label_fontsize)\n",
    "    plt.legend(legend[1], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    cls_report_print = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    cls_report = classification_report(test_generator.classes, y_classes, target_names=classes, output_dict=True)\n",
    "    \n",
    "    if print_report: \n",
    "        print(cls_report_print)\n",
    "    return y_preds, y_classes, CM, cls_report, cls_report_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, title, xlabel=\"Epoch\", ylabel=\"Value\", title_fontsize=14, label_fontsize=12, subplot_no=0):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, title, fig_size=(10, 8), xlabel=[\"Epoch\", \"Epoch\"], ylabel=[\"Value\",\"Value\"], title_fontsize=14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    line_plot_over_epochs(array[0], title[0], xlabel=xlabel[0], ylabel=ylabel[0], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=121)\n",
    "    line_plot_over_epochs(array[1], title[1], xlabel=xlabel[1], ylabel=ylabel[1], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=122)\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=figsize, hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.show()\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_filename, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "        \n",
    "    model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "    if not os.path.isdir(model_path):\n",
    "        return None\n",
    "    \n",
    "    reset_graph(model)\n",
    "\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    accuracy, loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "    y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "\n",
    "    precision = cls_report[class_name]['precision'] *100\n",
    "    recall =  cls_report[class_name]['recall'] *100\n",
    "    f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "\n",
    "\n",
    "\n",
    "    results1[model_filename] = [accuracy, loss]\n",
    "    results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "    print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "    print(\"*\"*80)\n",
    "    show_confusion_matrix(test_generator, y_classes, classes)\n",
    "    print(cls_report_print)\n",
    "    print(\"%s%.2f%s\"% (\"Current Accuracy: \", accuracy, \"%\"))\n",
    "    print(\"%s%.2f\"% (\"Current Loss: \", loss))\n",
    "    print(\"%s%.2f%s\"% (\"Current Precision: \", precision, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current Recall: \", recall, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current F1_score: \", f1_score, \"%\"))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    \n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "\n",
    "    report = {\"Accuracy\" : accuracy, \n",
    "              \"Loss\" : loss,\n",
    "              \"Precision\" : precision,\n",
    "              \"Recall\": recall,\n",
    "              \"F1-Score\":f1_score}\n",
    "\n",
    "\n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    filenames=[]\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    loss_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    \n",
    "    \n",
    "    best_accuracy=0\n",
    "    best_accuracy_file=\"\"\n",
    "    \n",
    "    best_loss=1000\n",
    "    best_loss_file=\"\"\n",
    "    \n",
    "    \n",
    "    best_precision=0\n",
    "    best_precision_file=\"\"\n",
    "    \n",
    "    best_recall=0\n",
    "    best_recall_file=\"\"\n",
    "    \n",
    "    best_f1_score=0\n",
    "    best_f1_score_file=\"\"\n",
    "    \n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    model = None\n",
    "    reset_graph(model)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for model_filename in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "            \n",
    "            current_accuracy, current_loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "            y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "            \n",
    "            current_precision = cls_report[class_name]['precision'] *100\n",
    "            current_recall =  cls_report[class_name]['recall'] *100\n",
    "            current_f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "            \n",
    "            filenames.append(model_file)\n",
    "            \n",
    "            accuracy_list.append(current_accuracy)\n",
    "            loss_list.append(current_loss)\n",
    "            \n",
    "            precision_list.append(current_precision)\n",
    "            recall_list.append(current_recall)\n",
    "            f1_score_list.append(current_f1_score)\n",
    "            \n",
    "            \n",
    "            results1[model_filename] = [current_accuracy, current_loss]\n",
    "            results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "                \n",
    "            if current_accuracy>=best_accuracy:\n",
    "                best_accuracy=current_accuracy\n",
    "                best_accuracy_file=model_filename\n",
    "\n",
    "            if current_loss<=best_loss:\n",
    "                best_loss=current_loss\n",
    "                best_loss_file=model_filename\n",
    "                \n",
    "            \n",
    "            if current_precision>=best_precision:\n",
    "                best_precision=current_precision\n",
    "                best_precision_file=model_filename\n",
    "\n",
    "            if current_recall>=best_recall:\n",
    "                best_recall=current_recall\n",
    "                best_recall_file=model_filename\n",
    "                \n",
    "            if current_f1_score>=best_f1_score:\n",
    "                best_f1_score=current_f1_score\n",
    "                best_f1_score_file=model_filename\n",
    "                    \n",
    "\n",
    "            if details or i%5==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "                print(\"*\"*80)\n",
    "                show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                print(cls_report_print)\n",
    "                print(\"%s%.2f%s\"% (\"Current Accuracy: \", current_accuracy, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Current Loss: \", current_loss))\n",
    "                print(\"%s%.2f%s\"% (\"Current Precision: \", current_precision, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current Recall: \", current_recall, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current F1_score: \", current_f1_score, \"%\"))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "    \n",
    "    report = {\"Best Accuracy\" : [best_accuracy, best_accuracy_file], \n",
    "                   \"Best Loss\" : [best_loss, best_loss_file],\n",
    "                   \"Best Precision\" : [best_precision, best_precision_file],\n",
    "                   \"Best Recall\": [best_recall, best_recall_file],\n",
    "                   \"Best F1-Score\":[best_f1_score, best_f1_score_file]}\n",
    "    \n",
    "    \n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-03 12:46:09\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-23dd3853590a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mreset_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "date_time(x)\n",
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train_final\"\n",
    "testing_dir = input_directory+ r\"test_final\"\n",
    "validation_dir = input_directory+ r\"validation_final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "fig_size = (18,4)\n",
    "# fig_size = (4,2)\n",
    "# title_fontsize=14\n",
    "title_fontsize=13\n",
    "# label_fontsize=12\n",
    "label_fontsize=13\n",
    "title=\"Number of Cases\"\n",
    "\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=fig_size, title_fontsize = title_fontsize, label_fontsize=label_fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "norm=255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "# shear_range=0.1\n",
    "zoom_range=0.2\n",
    "# zoom_range=0.1\n",
    "horizontal_flip=True\n",
    "\n",
    "\n",
    "# flow from directory function\n",
    "# Target Image dimention\n",
    "# target_size=(224, 224) # used previously\n",
    "target_size=(299, 299) # default expected image dimension for inceptionv3\n",
    "\n",
    "# Batch size\n",
    "# train\n",
    "batch_size=32\n",
    "# batch_size=64\n",
    "# batch_size=128\n",
    "\n",
    "# validation\n",
    "validation_batch_size=batch_size\n",
    "# validation_batch_size=1\n",
    "# test\n",
    "test_batch_size=batch_size\n",
    "# test_batch_size=1\n",
    "\n",
    "# shuffle\n",
    "# test\n",
    "test_shuffle=False\n",
    "\n",
    "# validation split for train\n",
    "validation_split=0.0\n",
    "\n",
    "# class mode\n",
    "# class_mode='binary'\n",
    "class_mode='categorical'\n",
    "# class_mode='sparse'\n",
    "\n",
    "\n",
    "classes = ['Normal', 'Cancer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132016 images belonging to 2 classes.\n",
      "Found 44005 images belonging to 2 classes.\n",
      "Found 44005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, target_size, classes, class_mode=class_mode, batch_size=batch_size, rescale=rescale, shear_range=shear_range, zoom_range=zoom_range, horizontal_flip=horizontal_flip)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=validation_batch_size, rescale=rescale)       \n",
    "\n",
    "test_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=test_batch_size, shuffle = test_shuffle, rescale=rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Adjustmanet for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "class_weight=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model and log output directory\n",
    "# model_dir=output_directory + r\"models/\"+time.strftime('%Y%m%d%H%M%S')+\"/\"\n",
    "model_dir=output_directory + r\"models/\"+time.strftime('%Y-%m-%d %H--%M--%S')+\"/\"\n",
    "# log_dir=output_directory + r\"logs/\"+time.strftime('%Y%m%d%H%M%S')\n",
    "log_dir=output_directory + r\"logs/\"+time.strftime('%Y-%m-%d %H--%M--%S')\n",
    "\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "\n",
    "\n",
    "init_model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "model_file=model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "retrain_model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(3,150,150)\n",
    "activation='relu'\n",
    "activation2='sigmoid'\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "pool_size=(2, 2)\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "init_optimizer=optimizers.Adam()\n",
    "# init_optimizer=optimizers.Adam(0.000001)\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_layers=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "# optimizer=optimizers.Adam(0.1)\n",
    "# optimizer=optimizers.Adam(0.01)\n",
    "# optimizer=optimizers.Adam(0.001)\n",
    "# optimizer=optimizers.Adam(0.00001)\n",
    "optimizer=optimizers.Adam(0.00001, decay=1e-7)\n",
    "\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "# metrics=['mae', 'acc']\n",
    "# metrics=['mse', 'acc']\n",
    "# metrics=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "# epochs = 30 #######original\n",
    "epochs = 10\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "# verbose=0\n",
    "verbose=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# base_logger\n",
    "base_logger_stateful_metrics=None\n",
    "\n",
    "# TerminateOnNaN\n",
    "\n",
    "# ProgbarLogger\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "\n",
    "# History\n",
    "\n",
    "# LearningRateScheduler\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "\n",
    "# CSVLogger\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "# ck_monitor='val_acc'\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "# red_lr_factor=0.1 # default\n",
    "red_lr_factor=0.5 # default\n",
    "# red_lr_patience=10\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_monitor = 'val_acc'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Callbacks\n",
    "#### ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard, \n",
    "#### BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger, checkpoint, reduce_lr, early_stopping, tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger]init_callbacks = None\n",
    "init_callbacks = None\n",
    "# init_callbacks = [checkpoint, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history, CSV_logger]\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "\n",
    "\n",
    "# callbacks = None\n",
    "# callbacks = [checkpoint, tensorboard]\n",
    "###callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retrain Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain_callbacks = None\n",
    "# retrain_callbacks = [checkpoint, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-03 12:49:37\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 3 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 3 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 3 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, None, None, 3 9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 3 96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 3 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 6 18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 6 192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 6 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 8 5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 8 240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 8 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, None, None, 1 138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, None, 1 576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 1 0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, None, 6 192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 6 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, None, None, 9 55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, None, 4 144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, None, 9 288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 4 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 9 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, None, None, 1 0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, None, None, 6 76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, None, None, 9 82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, None, 6 192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, None, 6 192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, None, 9 288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, None, 3 96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 6 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 6 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 9 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 3 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, None, 6 192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 6 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, None, None, 9 55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, None, 4 144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, None, 9 288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 4 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 9 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, None, None, 6 76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, None, None, 9 82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, None, 6 192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, None, 6 192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, None, 9 288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, None, 6 192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 6 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 6 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 9 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 6 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, None, 6 192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 6 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, None, None, 9 55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, None, None, 4 144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, None, 9 288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 4 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 9 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, None, None, 6 76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, None, None, 9 82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, None, 6 192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, None, 6 192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, None, 9 288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, None, 6 192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 6 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 6 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 9 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 6 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, None, 6 192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 6 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, None, None, 9 55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, None, None, 9 288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 9 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, None, None, 9 82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, None, 3 1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, None, None, 9 288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 3 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 9 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, None, None, 1 384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, None, None, 1 114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, None, None, 1 384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, None, None, 1 114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, None, None, 1 384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, None, None, 1 384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, None, None, 1 114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, None, None, 1 114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, None, None, 1 384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, None, None, 1 384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, None, None, 1 172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 1 172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, None, None, 1 576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, None, None, 1 576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, None, None, 1 576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, None, None, 1 576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, None, None, 1 480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 1 179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, None, None, 1 480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 1 179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, None, None, 1 480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, None, None, 1 480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 1 179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 1 179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, None, None, 1 480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, None, None, 1 480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 1 215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, None, 1 215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, None, None, 1 576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, None, None, 1 576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, None, None, 1 576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, None, None, 1 480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 1 179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, None, None, 1 480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 1 179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, None, None, 1 480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, None, None, 1 480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 1 179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 1 179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, None, None, 1 480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, None, None, 1 480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 1 215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 1 215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, None, None, 1 576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, None, None, 1 576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, None, None, 1 576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, None, None, 1 576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, None, None, 1 576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 1 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, None, None, 1 258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, None, None, 1 576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 1 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, None, None, 1 258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, None, None, 1 576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, None, None, 1 576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 1 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 1 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, None, None, 1 258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, None, None, 1 258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, None, None, 1 576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, None, None, 1 576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 1 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 1 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, None, None, 1 258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, None, None, 1 258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, None, None, 1 576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, None, None, 1 576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, None, None, 1 576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 1 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 1 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, None, None, 1 576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 1 0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, None, None, 1 258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, None, None, 1 258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, None, None, 1 576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, None, None, 1 576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 1 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 1 0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, None, None, 3 552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, None, None, 1 331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, None, None, 3 960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, None, None, 1 576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 3 0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 1 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, None, None, 4 1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 4 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, None, None, 3 1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, None, None, 3 1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, None, None, 3 1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 3 0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 3 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, None, None, 3 1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, None, None, 3 1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, None, 3 1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, None, 3 1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, None, None, 3 960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 3 0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 3 0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 3 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 3 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, None, 1 576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 3 0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 7 0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 1 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, None, 4 1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 4 0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, None, None, 3 1548288     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, None, 3 1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, None, 3 1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 3 0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 3 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, None, 3 1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, None, 3 1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, None, 3 1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, None, 3 1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, None, 3 960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 3 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 3 0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 3 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 3 0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, None, 1 576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 3 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 7 0           activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 1 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_180[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            2050        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 13,215,106\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n",
      "Timestamp: 2018-12-03 12:50:34\n"
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "date_time(1)\n",
    "init_epochs = 100\n",
    "print_layers=False\n",
    "model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, init_optimizer, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)\n",
    "main_model = model\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_report=True\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-03 12:51:19\n",
      "Epoch 1/10\n",
      "60/60 [==============================] - 143s 2s/step - loss: 0.4944 - acc: 0.7932 - val_loss: 1.4129 - val_acc: 0.7031\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 93s 2s/step - loss: 0.3768 - acc: 0.8490 - val_loss: 1.1931 - val_acc: 0.6375\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 102s 2s/step - loss: 0.3773 - acc: 0.8396 - val_loss: 0.9169 - val_acc: 0.6922\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 108s 2s/step - loss: 0.3274 - acc: 0.8635 - val_loss: 0.9065 - val_acc: 0.6406\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 108s 2s/step - loss: 0.3215 - acc: 0.8625 - val_loss: 0.7984 - val_acc: 0.7188\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 113s 2s/step - loss: 0.3220 - acc: 0.8708 - val_loss: 0.4847 - val_acc: 0.8047\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 130s 2s/step - loss: 0.3133 - acc: 0.8703 - val_loss: 0.8374 - val_acc: 0.7469\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 104s 2s/step - loss: 0.2844 - acc: 0.8859 - val_loss: 0.8692 - val_acc: 0.6906\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 101s 2s/step - loss: 0.3081 - acc: 0.8719 - val_loss: 1.0028 - val_acc: 0.6734\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 98s 2s/step - loss: 0.2765 - acc: 0.8922 - val_loss: 0.8125 - val_acc: 0.6828\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Timestamp: 2018-12-03 13:11:16\n"
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "\n",
    "# epochs=100\n",
    "# optimizer=optimizers.adam(lr=0.0001)\n",
    "# model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "# tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "###################main################\n",
    "# date_time(1)\n",
    "# history = model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch = steps_per_epoch,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=callbacks,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_steps,\n",
    "#     class_weight=class_weight)\n",
    "\n",
    "# date_time(1)\n",
    " \n",
    "    \n",
    "###################test####################\n",
    "date_time(1)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 60,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=20,\n",
    "    class_weight=class_weight)\n",
    "\n",
    "date_time(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "title = ['Model accuracy', 'Model loss']\n",
    "\n",
    "xlabel = ['Epoch', 'Epoch']\n",
    "ylabel = ['Accuracy', 'Loss']\n",
    "\n",
    "legend = ['Train', 'Val']\n",
    "\n",
    "fig_size=(15, 5)\n",
    "\n",
    "\n",
    "title_fontsize=17\n",
    "label_fontsize=15\n",
    "\n",
    "plot_history(history, plot_val, title, xlabel, ylabel, fig_size=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376/1376 [==============================] - 777s 565ms/step\n"
     ]
    }
   ],
   "source": [
    "result  = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7744602367967628\n",
      "69.48301329421477 %\n"
     ]
    }
   ],
   "source": [
    "print(result[0])\n",
    "print(result[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376/1376 [==============================] - 500s 363ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes=y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-03 13:47:38\n"
     ]
    }
   ],
   "source": [
    "date_time(1)\n",
    "\n",
    "details = True\n",
    "class_name = \"Cancer\"\n",
    "\n",
    "report_type = \"full\"\n",
    "results1, results2, report = test_all_models(model_dir, details, report_type, classes, class_name=class_name)\n",
    "\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename_list=[]\n",
    "model_file_path_list=[]\n",
    "for model_filename in results2:\n",
    "    model_filename_list.append(model_filename)\n",
    "    model_file_path_list.append(model_dir+model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_names = ['Normal-precision', 'Normal-recall', 'Normal-f1-score', \n",
    "                     'Cancer-precision','Cancer-recall', 'Cancer-f1-score', \n",
    "                     'micro avg-precision', 'micro avg-recall', 'micro avg-f1-score', \n",
    "                     'macro avg-precision', 'macro avg-recall', 'macro avg-f1-score', \n",
    "                     'weighted avg-precision', 'weighted avg-recall', 'weighted avg-f1-score',\n",
    "                     'Accuracy', 'Loss']\n",
    "metric_array_list=[]\n",
    "\n",
    "\n",
    "# 0\n",
    "negative_precision_list = [results2[i][1]['Normal']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_precision_list)\n",
    "\n",
    "# 1\n",
    "negative_recall_list = [results2[i][1]['Normal']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_recall_list)\n",
    "\n",
    "# 2\n",
    "negative_f1_score_list = [results2[i][1]['Normal']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "# 3\n",
    "positive_precision_list = [results2[i][1]['Cancer']['precision'] for i in results2]\n",
    "metric_array_list.append(positive_precision_list)\n",
    "\n",
    "# 4\n",
    "positive_recall_list = [results2[i][1]['Cancer']['recall'] for i in results2]\n",
    "metric_array_list.append(positive_recall_list)\n",
    "\n",
    "# 5\n",
    "positive_f1_score_list = [results2[i][1]['Cancer']['f1-score'] for i in results2]\n",
    "metric_array_list.append(positive_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 6\n",
    "micro_precision_list = [results2[i][1]['micro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(micro_precision_list)\n",
    "\n",
    "# 7\n",
    "micro_recall_list = [results2[i][1]['micro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(micro_recall_list)\n",
    "\n",
    "# 8\n",
    "micro_f1_score_list = [results2[i][1]['micro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(micro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 9\n",
    "macro_precision_list = [results2[i][1]['macro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(macro_precision_list)\n",
    "\n",
    "# 10\n",
    "macro_recall_list = [results2[i][1]['macro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(macro_recall_list)\n",
    "\n",
    "# 11\n",
    "macro_f1_score_list = [results2[i][1]['macro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(macro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 12\n",
    "weighted_precision_list = [results2[i][1]['weighted avg']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 13\n",
    "weighted_recall_list = [results2[i][1]['weighted avg']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 14\n",
    "weighted_f1_score_list = [results2[i][1]['weighted avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 15\n",
    "accuracy_list = [results1[i][0] for i in results1]\n",
    "metric_array_list.append(acc)\n",
    "\n",
    "# 16\n",
    "loss_list = [results1[i][1]for i in results1]\n",
    "metric_array_list.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_list_percent = metric_array_list\n",
    "num_metrics = len(metric_array_list)\n",
    "for i in range(num_metrics):\n",
    "    if i!=16:\n",
    "        metric_array_list_percent[i] = [i*100 for i in metric_array_list_norm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_list_norm = metric_array_list\n",
    "for i in range(len(metric_array_list)):\n",
    "    m=max(metric_array_list[i])\n",
    "    metric_array_list_norm[i] = [i/m for i in metric_array_list_norm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_index = [1,2,7,8,10,11]\n",
    "plot_index = [2, 3,4,5, 12, 13, 14, 15]\n",
    "\n",
    "# plot_index = [2, 3,4,5, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col = 12\n",
    "figsize_row = 4\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'Large'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_plot = False\n",
    "# seperate_plot = True\n",
    "\n",
    "filter_skip = False\n",
    "\n",
    "filter_plot = False\n",
    "filter_plot = True\n",
    "\n",
    "length=len(metric_array_list)\n",
    "num_epochs=len(results2)\n",
    "x = np.arange(num_epochs)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(18, 12), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "for i in range(length):\n",
    "    if not filter_plot or i in plot_index:\n",
    "        if seperate_plot:  \n",
    "            fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "            plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "            \n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Score (100%)\")\n",
    "            plt.yticks(np.arange(0, 100, 5))\n",
    "            plt.xticks(np.arange(0, num_epochs, 1))\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.ylim([min(metric_array_list_percent[i]),max(metric_array_list_percent[i])])\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.plot(x, metric_array_list[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "        \n",
    "\n",
    "            \n",
    "if not seperate_plot:\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Val\")\n",
    "    plt.yticks(np.arange(0, 100, 5))\n",
    "    plt.xticks(np.arange(0, num_epochs, 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col=10\n",
    "figsize_row=3\n",
    "fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "\n",
    "\n",
    "x = np.arange(len(results1))\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x, acc, label=\"Accuarcy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score(100%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x, loss, label= \"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [3,13,17, 18]\n",
    "num_model = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metric_array_list_percent)):\n",
    "    print(\"%6s%10s%.2f\"%(metric_array_names[i],\":\", metric_array_list_percent[i][num_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir=\"data\\\\output\\\\models\\\\20181201035451\\\\\"\n",
    "# model=keras.models.load_model(model_dir+\"30-val_acc-0.85-val_loss-0.66.hdf5\")\n",
    "\n",
    "model_path = model_file_path_list[num_model]\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report=True)\n",
    "y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Normal', 'PNEUMONIA']\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM , figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Retraining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "# optimizer=optimizers.Adam(0.1)\n",
    "# optimizer=optimizers.Adam(0.01)\n",
    "# optimizer=optimizers.Adam(0.001)\n",
    "# optimizer=optimizers.Adam(0.00001)\n",
    "# optimizer=optimizers.Adam(0.00001, decay=1e-7)\n",
    "\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "# metrics=['mae', 'acc']\n",
    "# metrics=['mse', 'acc']\n",
    "# metrics=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrainning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs = 30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# base_logger\n",
    "base_logger_stateful_metrics=None\n",
    "\n",
    "# TerminateOnNaN\n",
    "\n",
    "# ProgbarLogger\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "\n",
    "# History\n",
    "\n",
    "# LearningRateScheduler\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "\n",
    "# CSVLogger\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "# ck_monitor='val_acc'\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "red_lr_patience=10\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Callbacks\n",
    "#### ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard, \n",
    "#### BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger, checkpoint, reduce_lr, early_stopping, tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retrain Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain_callbacks = None\n",
    "# retrain_callbacks = [checkpoint, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
