{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Histopathologic Cancer Detection using Convolutional Neural Network, and Transfer Learning.\n",
    "Description      : 1. Detected Cancer from Histopathologic images by retraining pretrained model “InceptionV3” with                            250000+ images of X-ray (6GB).\n",
    "                   2. For retraining, removed output layers, freezed first few layers and Fine-tuned model for two new label                   classes (Cancer and Normal).\n",
    "                   3. Attained testing accuracy 69.55 and loss 1.10.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.28.2018\n",
    "Comments         : Please use Anaconda editor for convenience.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Histopathologic-Cancer-Detection>Histopathologic Cancer Detection(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Histopathologic Cancer Detection\n",
    "Dataset Link     : <a href=https://www.kaggle.com/c/histopathologic-cancer-detection>Histopathologic Cancer Detection (Kaggle)</a>\n",
    "                 : <a href=https://github.com/basveeling/pcam> PatchCamelyon (PCam) (GitHub)</a>\n",
    "                 : <a href=https://camelyon16.grand-challenge.org/Data>CAMELYON16 challenge Dataset (Original Dataset)</a>\n",
    "                 \n",
    "Original Paper   : <a href=https://jamanetwork.com/journals/jama/fullarticle/2665774>Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer</a> \n",
    "                   Authors: Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes van Diest \n",
    "                   JAMA (The Journal of the American Medical Association)\n",
    "                   <cite>\n",
    "                   Ehteshami Bejnordi B, Veta M, Johannes van Diest P, et al. Diagnostic Assessment of Deep Learning                        Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA.                                     2017;318(22):2199–2210. doi:10.1001/jama.2017.14585\n",
    "                   </cite>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Histopathologic Cancer Detection\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 220,025 (5.72 Gigabyte (GB))\n",
    "                          Training   : 132,016 (3.43 Gigabyte (GB))\n",
    "                          Validation : 44,005  (1.14 Gigabyte (GB))\n",
    "                          Testing    : 44,004  (1.14 Gigabyte (GB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 32\n",
    "Number of Epochs        : 20\n",
    "Training Time           : 1 day and 8 hour (33 Hours)\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 69.55%\n",
    "Loss                    : 1.10\n",
    "<!--Precision               : -->\n",
    "Recall                  : \n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Deletes file, if file exists \n",
    "def remove_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except:\n",
    "            print(\"Could not remove file : \", filename)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time for given type of representation\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "               \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "\n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, title, xlabel, ylabel, figsize=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=subplot_no)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    count_bar_plot(training_dir, title +\" (Training)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=131)\n",
    "    count_bar_plot(validation_dir, title +\" (Validation)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=132)\n",
    "    count_bar_plot(testing_dir, title +\" (Testing)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=133)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, target_size, classes, class_mode='categorical', batch_size=1, shuffle=True, rescale=None, shear_range=0.0, zoom_range=0.0, horizontal_flip=False, validation_split=0.0):       \n",
    "    datagen = ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            validation_split=validation_split)     \n",
    "    \n",
    "    image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=target_size,\n",
    "            classes = classes,\n",
    "            class_mode=class_mode,\n",
    "            batch_size=batch_size)\n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, optimizer, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        # compile model with loss, optimizer and metrics \n",
    "        model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "        # train the model on the new data for a few epochs\n",
    "        model.fit_generator(train_generator,\n",
    "                            steps_per_epoch = len(train_generator),\n",
    "                            epochs=epochs,\n",
    "                            # verbose=verbose, \n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=len(validation_generator),\n",
    "                            class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    if not callbacks:\n",
    "        model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "        tensorboard.set_model(model) \n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, title, xlabel, ylabel, legend=[['Train', 'Val'], ['Train', 'Val']], fig_size=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    plt.title(title[0], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[0], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[0], fontsize=label_fontsize)\n",
    "    plt.legend(legend[0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    plt.title(title[1], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[1], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[1], fontsize=label_fontsize)\n",
    "    plt.legend(legend[1], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    cls_report_print = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    cls_report = classification_report(test_generator.classes, y_classes, target_names=classes, output_dict=True)\n",
    "    \n",
    "    if print_report: \n",
    "        print(cls_report_print)\n",
    "    return y_preds, y_classes, CM, cls_report, cls_report_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, title, xlabel=\"Epoch\", ylabel=\"Value\", title_fontsize=14, label_fontsize=12, subplot_no=0):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, title, fig_size=(10, 8), xlabel=[\"Epoch\", \"Epoch\"], ylabel=[\"Value\",\"Value\"], title_fontsize=14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    line_plot_over_epochs(array[0], title[0], xlabel=xlabel[0], ylabel=ylabel[0], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=121)\n",
    "    line_plot_over_epochs(array[1], title[1], xlabel=xlabel[1], ylabel=ylabel[1], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=122)\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=figsize, hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.show()\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_filename, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "        \n",
    "    model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "    if not os.path.isdir(model_path):\n",
    "        return None\n",
    "    \n",
    "    reset_graph(model)\n",
    "\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    accuracy, loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "    y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "\n",
    "    precision = cls_report[class_name]['precision'] *100\n",
    "    recall =  cls_report[class_name]['recall'] *100\n",
    "    f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "\n",
    "\n",
    "\n",
    "    results1[model_filename] = [accuracy, loss]\n",
    "    results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "    print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "    print(\"*\"*80)\n",
    "    show_confusion_matrix(test_generator, y_classes, classes)\n",
    "    print(cls_report_print)\n",
    "    print(\"%s%.2f%s\"% (\"Current Accuracy: \", accuracy, \"%\"))\n",
    "    print(\"%s%.2f\"% (\"Current Loss: \", loss))\n",
    "    print(\"%s%.2f%s\"% (\"Current Precision: \", precision, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current Recall: \", recall, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current F1_score: \", f1_score, \"%\"))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    \n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "\n",
    "    report = {\"Accuracy\" : accuracy, \n",
    "              \"Loss\" : loss,\n",
    "              \"Precision\" : precision,\n",
    "              \"Recall\": recall,\n",
    "              \"F1-Score\":f1_score}\n",
    "\n",
    "\n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    filenames=[]\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    loss_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    \n",
    "    \n",
    "    best_accuracy=0\n",
    "    best_accuracy_file=\"\"\n",
    "    \n",
    "    best_loss=1000\n",
    "    best_loss_file=\"\"\n",
    "    \n",
    "    \n",
    "    best_precision=0\n",
    "    best_precision_file=\"\"\n",
    "    \n",
    "    best_recall=0\n",
    "    best_recall_file=\"\"\n",
    "    \n",
    "    best_f1_score=0\n",
    "    best_f1_score_file=\"\"\n",
    "    \n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    model = None\n",
    "    reset_graph(model)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for model_filename in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "            \n",
    "            current_accuracy, current_loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "            y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "            \n",
    "            current_precision = cls_report[class_name]['precision'] *100\n",
    "            current_recall =  cls_report[class_name]['recall'] *100\n",
    "            current_f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "            \n",
    "            filenames.append(model_file)\n",
    "            \n",
    "            accuracy_list.append(current_accuracy)\n",
    "            loss_list.append(current_loss)\n",
    "            \n",
    "            precision_list.append(current_precision)\n",
    "            recall_list.append(current_recall)\n",
    "            f1_score_list.append(current_f1_score)\n",
    "            \n",
    "            \n",
    "            results1[model_filename] = [current_accuracy, current_loss]\n",
    "            results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "                \n",
    "            if current_accuracy>=best_accuracy:\n",
    "                best_accuracy=current_accuracy\n",
    "                best_accuracy_file=model_filename\n",
    "\n",
    "            if current_loss<=best_loss:\n",
    "                best_loss=current_loss\n",
    "                best_loss_file=model_filename\n",
    "                \n",
    "            \n",
    "            if current_precision>=best_precision:\n",
    "                best_precision=current_precision\n",
    "                best_precision_file=model_filename\n",
    "\n",
    "            if current_recall>=best_recall:\n",
    "                best_recall=current_recall\n",
    "                best_recall_file=model_filename\n",
    "                \n",
    "            if current_f1_score>=best_f1_score:\n",
    "                best_f1_score=current_f1_score\n",
    "                best_f1_score_file=model_filename\n",
    "                    \n",
    "\n",
    "            if details or i%5==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "                print(\"*\"*80)\n",
    "                show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                print(cls_report_print)\n",
    "                print(\"%s%.2f%s\"% (\"Current Accuracy: \", current_accuracy, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Current Loss: \", current_loss))\n",
    "                print(\"%s%.2f%s\"% (\"Current Precision: \", current_precision, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current Recall: \", current_recall, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current F1_score: \", current_f1_score, \"%\"))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "    \n",
    "    report = {\"Best Accuracy\" : [best_accuracy, best_accuracy_file], \n",
    "                   \"Best Loss\" : [best_loss, best_loss_file],\n",
    "                   \"Best Precision\" : [best_precision, best_precision_file],\n",
    "                   \"Best Recall\": [best_recall, best_recall_file],\n",
    "                   \"Best F1-Score\":[best_f1_score, best_f1_score_file]}\n",
    "    \n",
    "    \n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-455a2dc4cf83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreset_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train_final\"\n",
    "testing_dir = input_directory+ r\"test_final\"\n",
    "validation_dir = input_directory+ r\"validation_final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "fig_size = (18,4)\n",
    "# fig_size = (4,2)\n",
    "# title_fontsize=14\n",
    "title_fontsize=13\n",
    "# label_fontsize=12\n",
    "label_fontsize=13\n",
    "title=\"Number of Cases\"\n",
    "\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=fig_size, title_fontsize = title_fontsize, label_fontsize=label_fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "norm=255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "# shear_range=0.1\n",
    "zoom_range=0.2\n",
    "# zoom_range=0.1\n",
    "horizontal_flip=True\n",
    "\n",
    "\n",
    "# flow from directory function\n",
    "# Target Image dimention\n",
    "target_size=(224, 224)\n",
    "\n",
    "# Batch size\n",
    "# train\n",
    "# batch_size=32\n",
    "# batch_size=64\n",
    "batch_size=128\n",
    "\n",
    "# validation\n",
    "validation_batch_size=1\n",
    "# test\n",
    "test_batch_size=1\n",
    "\n",
    "# shuffle\n",
    "# test\n",
    "test_shuffle=False\n",
    "\n",
    "# validation split for train\n",
    "validation_split=0.0\n",
    "\n",
    "# class mode\n",
    "# class_mode='binary'\n",
    "class_mode='categorical'\n",
    "# class_mode='sparse'\n",
    "\n",
    "\n",
    "classes = ['Normal', 'Cancer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132016 images belonging to 2 classes.\n",
      "Found 44005 images belonging to 2 classes.\n",
      "Found 44005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, target_size, classes, class_mode=class_mode, batch_size=batch_size, rescale=rescale, shear_range=shear_range, zoom_range=zoom_range, horizontal_flip=horizontal_flip)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=validation_batch_size, rescale=rescale)       \n",
    "\n",
    "test_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=test_batch_size, shuffle = test_shuffle, rescale=rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Adjustmanet for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "class_weight=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model and log output directory\n",
    "# model_dir=output_directory + r\"models/\"+time.strftime('%Y%m%d%H%M%S')+\"/\"\n",
    "model_dir=output_directory + r\"models/\"+time.strftime('%Y-%m-%d %H:%M:%S')+\"/\"\n",
    "# log_dir=output_directory + r\"logs/\"+time.strftime('%Y%m%d%H%M%S')\n",
    "log_dir=output_directory + r\"logs/\"+time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "\n",
    "\n",
    "init_model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "model_file=model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "retrain_model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(3,150,150)\n",
    "activation='relu'\n",
    "activation2='sigmoid'\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "pool_size=(2, 2)\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "init_optimizer=optimizers.Adam()\n",
    "# init_optimizer=optimizers.Adam(0.000001)\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_layers=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "# optimizer=optimizers.Adam(0.1)\n",
    "# optimizer=optimizers.Adam(0.01)\n",
    "# optimizer=optimizers.Adam(0.001)\n",
    "# optimizer=optimizers.Adam(0.00001)\n",
    "# optimizer=optimizers.Adam(0.00001, decay=1e-7)\n",
    "\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "# metrics=['mae', 'acc']\n",
    "# metrics=['mse', 'acc']\n",
    "# metrics=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs = 30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# base_logger\n",
    "base_logger_stateful_metrics=None\n",
    "\n",
    "# TerminateOnNaN\n",
    "\n",
    "# ProgbarLogger\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "\n",
    "# History\n",
    "\n",
    "# LearningRateScheduler\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "\n",
    "# CSVLogger\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "# ck_monitor='val_acc'\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "red_lr_patience=10\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Callbacks\n",
    "#### ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard, \n",
    "#### BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger, checkpoint, reduce_lr, early_stopping, tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger]init_callbacks = None\n",
    "init_callbacks = None\n",
    "# init_callbacks = [checkpoint, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history, CSV_logger]\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "\n",
    "\n",
    "# callbacks = None\n",
    "# callbacks = [checkpoint, tensorboard]\n",
    "###callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retrain Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain_callbacks = None\n",
    "# retrain_callbacks = [checkpoint, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 13,215,106\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "init_epochs = 100\n",
    "print_layers=False\n",
    "model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, init_optimizer, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)\n",
    "main_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_report=True\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 5117s 5s/step - loss: 0.2744 - acc: 0.8902 - val_loss: 0.9761 - val_acc: 0.6678\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 5142s 5s/step - loss: 0.2200 - acc: 0.9130 - val_loss: 1.2123 - val_acc: 0.6421\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 5278s 5s/step - loss: 0.2008 - acc: 0.9210 - val_loss: 1.1393 - val_acc: 0.6439\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4839s 5s/step - loss: 0.1890 - acc: 0.9262 - val_loss: 1.4130 - val_acc: 0.6404\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 4843s 5s/step - loss: 0.1800 - acc: 0.9303 - val_loss: 1.3389 - val_acc: 0.6432\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 5127s 5s/step - loss: 0.1715 - acc: 0.9330 - val_loss: 1.4112 - val_acc: 0.6264\n"
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "\n",
    "# epochs=100\n",
    "# optimizer=optimizers.adam(lr=0.0001)\n",
    "# model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "# tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "title = ['Model accuracy', 'Model loss']\n",
    "\n",
    "xlabel = ['Epoch', 'Epoch']\n",
    "ylabel = ['Accuracy', 'Loss']\n",
    "\n",
    "legend = ['Train', 'Val']\n",
    "\n",
    "fig_size=(15, 5)\n",
    "\n",
    "\n",
    "title_fontsize=17\n",
    "label_fontsize=15\n",
    "\n",
    "plot_history(history, plot_val, title, xlabel, ylabel, fig_size=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = True\n",
    "class_name = \"Cancer\"\n",
    "\n",
    "report_type = \"full\"\n",
    "results1, results2, report = test_all_models(model_dir, details, report_type, classes, class_name=class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename_list=[]\n",
    "model_file_path_list=[]\n",
    "for model_filename in results2:\n",
    "    model_filename_list.append(model_filename)\n",
    "    model_file_path_list.append(model_dir+model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_names = ['Normal-precision', 'Normal-recall', 'Normal-f1-score', \n",
    "                     'Cancer-precision','Cancer-recall', 'Cancer-f1-score', \n",
    "                     'micro avg-precision', 'micro avg-recall', 'micro avg-f1-score', \n",
    "                     'macro avg-precision', 'macro avg-recall', 'macro avg-f1-score', \n",
    "                     'weighted avg-precision', 'weighted avg-recall', 'weighted avg-f1-score',\n",
    "                     'Accuracy', 'Loss']\n",
    "metric_array_list=[]\n",
    "\n",
    "\n",
    "# 0\n",
    "negative_precision_list = [results2[i][1]['Normal']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_precision_list)\n",
    "\n",
    "# 1\n",
    "negative_recall_list = [results2[i][1]['Normal']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_recall_list)\n",
    "\n",
    "# 2\n",
    "negative_f1_score_list = [results2[i][1]['Normal']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "# 3\n",
    "positive_precision_list = [results2[i][1]['Cancer']['precision'] for i in results2]\n",
    "metric_array_list.append(positive_precision_list)\n",
    "\n",
    "# 4\n",
    "positive_recall_list = [results2[i][1]['Cancer']['recall'] for i in results2]\n",
    "metric_array_list.append(positive_recall_list)\n",
    "\n",
    "# 5\n",
    "positive_f1_score_list = [results2[i][1]['Cancer']['f1-score'] for i in results2]\n",
    "metric_array_list.append(positive_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 6\n",
    "micro_precision_list = [results2[i][1]['micro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(micro_precision_list)\n",
    "\n",
    "# 7\n",
    "micro_recall_list = [results2[i][1]['micro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(micro_recall_list)\n",
    "\n",
    "# 8\n",
    "micro_f1_score_list = [results2[i][1]['micro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(micro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 9\n",
    "macro_precision_list = [results2[i][1]['macro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(macro_precision_list)\n",
    "\n",
    "# 10\n",
    "macro_recall_list = [results2[i][1]['macro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(macro_recall_list)\n",
    "\n",
    "# 11\n",
    "macro_f1_score_list = [results2[i][1]['macro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(macro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 12\n",
    "weighted_precision_list = [results2[i][1]['weighted avg']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 13\n",
    "weighted_recall_list = [results2[i][1]['weighted avg']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 14\n",
    "weighted_f1_score_list = [results2[i][1]['weighted avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 15\n",
    "accuracy_list = [results1[i][0] for i in results1]\n",
    "metric_array_list.append(acc)\n",
    "\n",
    "# 16\n",
    "loss_list = [results1[i][1]for i in results1]\n",
    "metric_array_list.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_list_percent = metric_array_list\n",
    "num_metrics = len(metric_array_list)\n",
    "for i in range(num_metrics):\n",
    "    if i!=16:\n",
    "        metric_array_list_percent[i] = [i*100 for i in metric_array_list_norm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_list_norm = metric_array_list\n",
    "for i in range(len(metric_array_list)):\n",
    "    m=max(metric_array_list[i])\n",
    "    metric_array_list_norm[i] = [i/m for i in metric_array_list_norm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_index = [1,2,7,8,10,11]\n",
    "plot_index = [2, 3,4,5, 12, 13, 14, 15]\n",
    "\n",
    "# plot_index = [2, 3,4,5, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col = 12\n",
    "figsize_row = 4\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'Large'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_plot = False\n",
    "# seperate_plot = True\n",
    "\n",
    "filter_skip = False\n",
    "\n",
    "filter_plot = False\n",
    "filter_plot = True\n",
    "\n",
    "length=len(metric_array_list)\n",
    "num_epochs=len(results2)\n",
    "x = np.arange(num_epochs)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(18, 12), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "for i in range(length):\n",
    "    if not filter_plot or i in plot_index:\n",
    "        if seperate_plot:  \n",
    "            fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "            plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "            \n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Score (100%)\")\n",
    "            plt.yticks(np.arange(0, 100, 5))\n",
    "            plt.xticks(np.arange(0, num_epochs, 1))\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.ylim([min(metric_array_list_percent[i]),max(metric_array_list_percent[i])])\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.plot(x, metric_array_list[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "        \n",
    "\n",
    "            \n",
    "if not seperate_plot:\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Val\")\n",
    "    plt.yticks(np.arange(0, 100, 5))\n",
    "    plt.xticks(np.arange(0, num_epochs, 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col=10\n",
    "figsize_row=3\n",
    "fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "\n",
    "\n",
    "x = np.arange(len(results1))\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x, acc, label=\"Accuarcy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score(100%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x, loss, label= \"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [3,13,17, 18]\n",
    "num_model = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metric_array_list_percent)):\n",
    "    print(\"%6s%10s%.2f\"%(metric_array_names[i],\":\", metric_array_list_percent[i][num_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir=\"data\\\\output\\\\models\\\\20181201035451\\\\\"\n",
    "# model=keras.models.load_model(model_dir+\"30-val_acc-0.85-val_loss-0.66.hdf5\")\n",
    "\n",
    "model_path = model_file_path_list[num_model]\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report=True)\n",
    "y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Normal', 'PNEUMONIA']\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM , figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Retraining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "# optimizer=optimizers.Adam(0.1)\n",
    "# optimizer=optimizers.Adam(0.01)\n",
    "# optimizer=optimizers.Adam(0.001)\n",
    "# optimizer=optimizers.Adam(0.00001)\n",
    "# optimizer=optimizers.Adam(0.00001, decay=1e-7)\n",
    "\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "# metrics=['mae', 'acc']\n",
    "# metrics=['mse', 'acc']\n",
    "# metrics=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrainning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs = 30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# base_logger\n",
    "base_logger_stateful_metrics=None\n",
    "\n",
    "# TerminateOnNaN\n",
    "\n",
    "# ProgbarLogger\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "\n",
    "# History\n",
    "\n",
    "# LearningRateScheduler\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "\n",
    "# CSVLogger\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "# ck_monitor='val_acc'\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "red_lr_patience=10\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Callbacks\n",
    "#### ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard, \n",
    "#### BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger, checkpoint, reduce_lr, early_stopping, tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retrain Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain_callbacks = None\n",
    "# retrain_callbacks = [checkpoint, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
